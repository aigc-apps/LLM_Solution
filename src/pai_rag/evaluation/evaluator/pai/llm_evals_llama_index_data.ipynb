{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b69e074a-7912-4933-bcfd-ab70410daf99",
   "metadata": {},
   "source": [
    "## LLM OpenAI Evaluations on LlamaIndex Data\n",
    "\n",
    "- Faithfulness\n",
    "- RAG correctness\n",
    "- Retriever Relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bb1c29-542e-4f32-b1df-448a36fa4768",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install https://pai-llm-evals.oss-cn-zhangjiakou.aliyuncs.com/sdk/package/pai_llm_evals-0.0.1-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f6e281-a429-4244-9ab0-da179cb99c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import nest_asyncio\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from getpass import getpass\n",
    "\n",
    "from pai.llm_eval.data.data_adapter import LlamaIndexDataAdapter\n",
    "from pai.llm_eval.data.data_reader import LlamaIndexDataReader\n",
    "from pai.llm_eval.evals.models.openai_model import OpenAIModel\n",
    "from pai.llm_eval.evals.default_templates import DefaultPromptTemplateCN\n",
    "from pai.llm_eval.evals.evaluators import LLMEvaluator\n",
    "from pai.llm_eval.evals.executors import run_evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d57d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "file_path = (\n",
    "    \"/home/xiaowen/xiaowen/github_code/PAI-RAG/example_data/pai_llm_eval_results.xlsx\"\n",
    ")\n",
    "csv_file_path = (\n",
    "    \"/home/xiaowen/xiaowen/github_code/PAI-RAG/example_data/pai_llm_eval_results.csv\"\n",
    ")\n",
    "\n",
    "# 从命令行参数获取文件名\n",
    "xlsx_file = file_path\n",
    "csv_file = csv_file_path\n",
    "\n",
    "# 读取 Excel 文件并转换为 CSV\n",
    "df = pd.read_excel(xlsx_file)\n",
    "df.to_csv(csv_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b125a20-d0e5-4837-a3d5-840c12caaf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read llama index data\n",
    "file_path = (\n",
    "    \"/home/xiaowen/xiaowen/github_code/PAI-RAG/example_data/pai_llm_eval_results.csv\"\n",
    ")\n",
    "data = LlamaIndexDataReader.read_data(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f40b4ca-8661-4235-b4e4-e3c1fdd5cfd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_input_data:\n",
      "    Unnamed: 0                             query  \\\n",
      "0           0                 组件化如何简化模型开发并提高效率？   \n",
      "1           1  如何通过Keras Layer类的组件化设计提高模型开发的效率？   \n",
      "\n",
      "                                  reference_contexts  \\\n",
      "0  ['为何需要组件化¶\\n1. 依靠动态可插拔的公共组件，方便为现有模型添加新特性。¶\\n过去...   \n",
      "1  ['添加新的特性将变得更加容易。¶\\n现在我们只需要为新的特征开发一个Keras Layer...   \n",
      "\n",
      "                                   reference_node_id  \\\n",
      "0  ['182bca8f8d785f74c7173ab47359a663164c408fe857...   \n",
      "1  ['13bed26b44134f96812e4f758bfa1b00b498c104ac42...   \n",
      "\n",
      "                                    reference_answer  \\\n",
      "0  组件化通过以下几个方面简化模型开发并提高效率：\\n\\n1. **动态可插拔性**：组件化允许...   \n",
      "1  通过Keras Layer类的组件化设计，模型开发的效率得以提高，主要体现在以下几个方面：\\...   \n",
      "\n",
      "                                     response_answer  \\\n",
      "0  组件化通过模块化和配置化的方法简化了模型开发流程。它允许开发者专注于设计独特的子模块（组件）...   \n",
      "1  通过Keras Layer类的组件化设计，模型开发效率提升体现在能够快速实验和迭代新特性。开...   \n",
      "\n",
      "                                       retrieved_ids  \\\n",
      "0  ['13bed26b44134f96812e4f758bfa1b00b498c104ac42...   \n",
      "1  ['182bca8f8d785f74c7173ab47359a663164c408fe857...   \n",
      "\n",
      "                                     retrieved_texts  \\\n",
      "0  ['添加新的特性将变得更加容易。¶\\n现在我们只需要为新的特征开发一个Keras Layer...   \n",
      "1  ['为何需要组件化¶\\n1. 依靠动态可插拔的公共组件，方便为现有模型添加新特性。¶\\n过去...   \n",
      "\n",
      "                             retrieved_scores  \n",
      "0  [0.09999999999999999, 0.09836065573770493]  \n",
      "1  [0.09918032786885246, 0.09918032786885246]  \n"
     ]
    }
   ],
   "source": [
    "# select the first two rows of data as the input\n",
    "eval_input_data = data[:2]\n",
    "print(f\"eval_input_data:\\n {eval_input_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415aa09e-caf5-47bd-9cbf-fa1769e6e0b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_data:\n",
      " defaultdict(<class 'list'>, {'llm': [{'idx': 0, 'input': '组件化如何简化模型开发并提高效率？', 'output': '组件化通过模块化和配置化的方法简化了模型开发流程。它允许开发者专注于设计独特的子模块（组件），这些组件可以独立开发和测试，然后在需要时轻松地组合和配置，就像拼积木一样。这种结构减少了代码重复，降低了出错风险，特别是对于不熟悉整个框架细节的新手来说，可以直接利用现成的组件，降低了学习曲线，从而提升了整体的开发效率。', 'reference': \"['为何需要组件化¶\\\\n1. 依靠动态可插拔的公共组件，方便为现有模型添加新特性。¶\\\\n过去一个新开发的公共可选模块，比如Dense Feature Embedding Layer、 SENet添加到现有模型中，需要修改所有模型的代码才能用上新的特性，过程繁琐易出错。随着模型数量和公共模块数量的增加，为所有模型集成所有公共可选模块将产生组合爆炸的不可控局面。组件化实现了底层公共模块与上层模型的解耦。\\\\n\\\\n2. 通过重组已有组件，实现“搭积木”式新模型开发。¶\\\\n很多模型之所以被称之为一个新的模型，是因为引入了一个或多个特殊的子模块（组件），然而这些子模块并不仅仅只能用在该模型中，通过组合各个不同的子模块可以轻易组装一个新的模型。组件化EasyRec支持通过配置化的方式搭建新的模型。\\\\n\\\\n3.']\"}, {'idx': 1, 'input': '如何通过Keras Layer类的组件化设计提高模型开发的效率？', 'output': '通过Keras Layer类的组件化设计，模型开发效率提升体现在能够快速实验和迭代新特性。开发者只需创建一个专门的Keras Layer类，定义其功能并在相应的package中导入，框架会自动将其纳入组件库。这样，新特性开发简化为开发单一模块，而无需深入理解EasyRec的全部细节。这加快了模型定制和实验的速度，提高了整体开发效率。', 'reference': \"['添加新的特性将变得更加容易。¶\\\\n现在我们只需要为新的特征开发一个Keras Layer类，并在指定package中添加import语句，框架就能自动识别并添加到组件库中，不需要额外操作。开发一个新的模型，只需要实现特殊的新模块，其余部分可以通过组件库中的已有组件拼装。新人不再需要熟悉EasyRec的方方面面就可以为框架添加功能，开发效率大大提高。']\"}], 'retrieve': [{'idx': 0, 'input': '组件化如何简化模型开发并提高效率？', 'reference': '添加新的特性将变得更加容易。¶\\\\n现在我们只需要为新的特征开发一个Keras Layer类，并在指定package中添加import语句，框架就能自动识别并添加到组件库中，不需要额外操作。开发一个新的模型，只需要实现特殊的新模块，其余部分可以通过组件库中的已有组件拼装。新人不再需要熟悉EasyRec的方方面面就可以为框架添加功能，开发效率大大提高。', 'reference_id': \"['182bca8f8d785f74c7173ab47359a663164c408fe857c44e11c94bea15e1627f']\", 'document_id': '13bed26b44134f96812e4f758bfa1b00b498c104ac42e0f9f34eb854c76938a0', 'document_score': 0.09999999999999999}, {'idx': 0, 'input': '组件化如何简化模型开发并提高效率？', 'reference': '为何需要组件化¶\\\\n1. 依靠动态可插拔的公共组件，方便为现有模型添加新特性。¶\\\\n过去一个新开发的公共可选模块，比如Dense Feature Embedding Layer、 SENet添加到现有模型中，需要修改所有模型的代码才能用上新的特性，过程繁琐易出错。随着模型数量和公共模块数量的增加，为所有模型集成所有公共可选模块将产生组合爆炸的不可控局面。组件化实现了底层公共模块与上层模型的解耦。\\\\n\\\\n2. 通过重组已有组件，实现“搭积木”式新模型开发。¶\\\\n很多模型之所以被称之为一个新的模型，是因为引入了一个或多个特殊的子模块（组件），然而这些子模块并不仅仅只能用在该模型中，通过组合各个不同的子模块可以轻易组装一个新的模型。组件化EasyRec支持通过配置化的方式搭建新的模型。\\\\n\\\\n3.', 'reference_id': \"['182bca8f8d785f74c7173ab47359a663164c408fe857c44e11c94bea15e1627f']\", 'document_id': '182bca8f8d785f74c7173ab47359a663164c408fe857c44e11c94bea15e1627f', 'document_score': 0.09836065573770493}, {'idx': 1, 'input': '如何通过Keras Layer类的组件化设计提高模型开发的效率？', 'reference': '为何需要组件化¶\\\\n1. 依靠动态可插拔的公共组件，方便为现有模型添加新特性。¶\\\\n过去一个新开发的公共可选模块，比如Dense Feature Embedding Layer、 SENet添加到现有模型中，需要修改所有模型的代码才能用上新的特性，过程繁琐易出错。随着模型数量和公共模块数量的增加，为所有模型集成所有公共可选模块将产生组合爆炸的不可控局面。组件化实现了底层公共模块与上层模型的解耦。\\\\n\\\\n2. 通过重组已有组件，实现“搭积木”式新模型开发。¶\\\\n很多模型之所以被称之为一个新的模型，是因为引入了一个或多个特殊的子模块（组件），然而这些子模块并不仅仅只能用在该模型中，通过组合各个不同的子模块可以轻易组装一个新的模型。组件化EasyRec支持通过配置化的方式搭建新的模型。\\\\n\\\\n3.', 'reference_id': \"['13bed26b44134f96812e4f758bfa1b00b498c104ac42e0f9f34eb854c76938a0']\", 'document_id': '182bca8f8d785f74c7173ab47359a663164c408fe857c44e11c94bea15e1627f', 'document_score': 0.09918032786885246}, {'idx': 1, 'input': '如何通过Keras Layer类的组件化设计提高模型开发的效率？', 'reference': '添加新的特性将变得更加容易。¶\\\\n现在我们只需要为新的特征开发一个Keras Layer类，并在指定package中添加import语句，框架就能自动识别并添加到组件库中，不需要额外操作。开发一个新的模型，只需要实现特殊的新模块，其余部分可以通过组件库中的已有组件拼装。新人不再需要熟悉EasyRec的方方面面就可以为框架添加功能，开发效率大大提高。', 'reference_id': \"['13bed26b44134f96812e4f758bfa1b00b498c104ac42e0f9f34eb854c76938a0']\", 'document_id': '13bed26b44134f96812e4f758bfa1b00b498c104ac42e0f9f34eb854c76938a0', 'document_score': 0.09918032786885246}]})\n"
     ]
    }
   ],
   "source": [
    "# adapt llama-index data\n",
    "tda = LlamaIndexDataAdapter()\n",
    "output_data = tda.convert(eval_input_data)\n",
    "print(f\"output_data:\\n {output_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e60bd2-cb61-44f2-94ba-e86e3d3dae2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'idx': 0,\n",
       "  'input': '组件化如何简化模型开发并提高效率？',\n",
       "  'output': '组件化通过模块化和配置化的方法简化了模型开发流程。它允许开发者专注于设计独特的子模块（组件），这些组件可以独立开发和测试，然后在需要时轻松地组合和配置，就像拼积木一样。这种结构减少了代码重复，降低了出错风险，特别是对于不熟悉整个框架细节的新手来说，可以直接利用现成的组件，降低了学习曲线，从而提升了整体的开发效率。',\n",
       "  'reference': \"['为何需要组件化¶\\\\n1. 依靠动态可插拔的公共组件，方便为现有模型添加新特性。¶\\\\n过去一个新开发的公共可选模块，比如Dense Feature Embedding Layer、 SENet添加到现有模型中，需要修改所有模型的代码才能用上新的特性，过程繁琐易出错。随着模型数量和公共模块数量的增加，为所有模型集成所有公共可选模块将产生组合爆炸的不可控局面。组件化实现了底层公共模块与上层模型的解耦。\\\\n\\\\n2. 通过重组已有组件，实现“搭积木”式新模型开发。¶\\\\n很多模型之所以被称之为一个新的模型，是因为引入了一个或多个特殊的子模块（组件），然而这些子模块并不仅仅只能用在该模型中，通过组合各个不同的子模块可以轻易组装一个新的模型。组件化EasyRec支持通过配置化的方式搭建新的模型。\\\\n\\\\n3.']\"},\n",
       " {'idx': 1,\n",
       "  'input': '如何通过Keras Layer类的组件化设计提高模型开发的效率？',\n",
       "  'output': '通过Keras Layer类的组件化设计，模型开发效率提升体现在能够快速实验和迭代新特性。开发者只需创建一个专门的Keras Layer类，定义其功能并在相应的package中导入，框架会自动将其纳入组件库。这样，新特性开发简化为开发单一模块，而无需深入理解EasyRec的全部细节。这加快了模型定制和实验的速度，提高了整体开发效率。',\n",
       "  'reference': \"['添加新的特性将变得更加容易。¶\\\\n现在我们只需要为新的特征开发一个Keras Layer类，并在指定package中添加import语句，框架就能自动识别并添加到组件库中，不需要额外操作。开发一个新的模型，只需要实现特殊的新模块，其余部分可以通过组件库中的已有组件拼装。新人不再需要熟悉EasyRec的方方面面就可以为框架添加功能，开发效率大大提高。']\"}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_data = output_data[\"retrieve\"]\n",
    "llm_data = output_data[\"llm\"]\n",
    "print(type(llm_data))\n",
    "llm_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4ca357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>reference</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>根据你提供的内容，以下是三个适合作为问答对数据集的问题：</td>\n",
       "      <td>[EasyRec是一个易于使用的推荐框架¶\\nEasyRec 实现了常见推荐任务中使用的最先...</td>\n",
       "      <td>根据提供的内容，以下是三个适合作为问答对数据集的问题及其答案：\\n\\n1. **问题**: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EasyRec 支持在哪些平台上运行？</td>\n",
       "      <td>[EasyRec是一个易于使用的推荐框架¶\\nEasyRec 实现了常见推荐任务中使用的最先...</td>\n",
       "      <td>EasyRec 支持在以下平台上运行：\\n\\n- MaxCompute\\n- 数据科学平台\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EasyRec 实现了哪些常见的推荐任务中的机器学习模型？</td>\n",
       "      <td>[EasyRec是一个易于使用的推荐框架¶\\nEasyRec 实现了常见推荐任务中使用的最先...</td>\n",
       "      <td>EasyRec 实现了以下常见的推荐任务中的机器学习模型：\\n\\n- 候选生成（匹配）\\n-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EasyRec 如何提高生成高性能模型的效率？</td>\n",
       "      <td>[EasyRec是一个易于使用的推荐框架¶\\nEasyRec 实现了常见推荐任务中使用的最先...</td>\n",
       "      <td>EasyRec 提高生成高性能模型的效率主要通过以下几个方面：\\n\\n1. **简单的配置*...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>这些问题都基于提供的内容，并且符合要求的具体性、明确性和避免指代不明确的原则。</td>\n",
       "      <td>[为何需要组件化¶\\n1. 依靠动态可插拔的公共组件，方便为现有模型添加新特性。¶\\n过去一...</td>\n",
       "      <td>根据提供的文档内容，以下是针对相关问题的回答：\\n\\n1. **为何需要组件化？**\\n  ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     input  \\\n",
       "0             根据你提供的内容，以下是三个适合作为问答对数据集的问题：   \n",
       "1                      EasyRec 支持在哪些平台上运行？   \n",
       "2            EasyRec 实现了哪些常见的推荐任务中的机器学习模型？   \n",
       "3                  EasyRec 如何提高生成高性能模型的效率？   \n",
       "4  这些问题都基于提供的内容，并且符合要求的具体性、明确性和避免指代不明确的原则。   \n",
       "\n",
       "                                           reference  \\\n",
       "0  [EasyRec是一个易于使用的推荐框架¶\\nEasyRec 实现了常见推荐任务中使用的最先...   \n",
       "1  [EasyRec是一个易于使用的推荐框架¶\\nEasyRec 实现了常见推荐任务中使用的最先...   \n",
       "2  [EasyRec是一个易于使用的推荐框架¶\\nEasyRec 实现了常见推荐任务中使用的最先...   \n",
       "3  [EasyRec是一个易于使用的推荐框架¶\\nEasyRec 实现了常见推荐任务中使用的最先...   \n",
       "4  [为何需要组件化¶\\n1. 依靠动态可插拔的公共组件，方便为现有模型添加新特性。¶\\n过去一...   \n",
       "\n",
       "                                              output  \n",
       "0  根据提供的内容，以下是三个适合作为问答对数据集的问题及其答案：\\n\\n1. **问题**: ...  \n",
       "1  EasyRec 支持在以下平台上运行：\\n\\n- MaxCompute\\n- 数据科学平台\\...  \n",
       "2  EasyRec 实现了以下常见的推荐任务中的机器学习模型：\\n\\n- 候选生成（匹配）\\n-...  \n",
       "3  EasyRec 提高生成高性能模型的效率主要通过以下几个方面：\\n\\n1. **简单的配置*...  \n",
       "4  根据提供的文档内容，以下是针对相关问题的回答：\\n\\n1. **为何需要组件化？**\\n  ...  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "qca_dataset = \"/home/xiaowen/xiaowen/github_code/PAI-RAG/localdata/eval_exp_data/storage__exp1/predicted_qca_dataset.json\"\n",
    "with open(qca_dataset, \"r\", encoding=\"utf-8\") as f:\n",
    "    qcas = json.load(f)\n",
    "    qcas = qcas[\"examples\"][0:5]\n",
    "\n",
    "# data = pd.read_json(qcas)\n",
    "response_df = pd.DataFrame(qcas)\n",
    "response_df\n",
    "response_eval_df = response_df[\n",
    "    [\"query\", \"predicted_contexts\", \"predicted_answer\"]\n",
    "].rename(\n",
    "    columns={\n",
    "        \"query\": \"input\",\n",
    "        \"predicted_answer\": \"output\",\n",
    "        \"predicted_contexts\": \"reference\",\n",
    "    }\n",
    ")\n",
    "response_eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bf8b2a-3225-4de3-9e5f-4bac32de0ecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>reference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>组件化如何简化模型开发并提高效率？</td>\n",
       "      <td>组件化通过模块化和配置化的方法简化了模型开发流程。它允许开发者专注于设计独特的子模块（组件）...</td>\n",
       "      <td>['为何需要组件化¶\\n1. 依靠动态可插拔的公共组件，方便为现有模型添加新特性。¶\\n过去...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>如何通过Keras Layer类的组件化设计提高模型开发的效率？</td>\n",
       "      <td>通过Keras Layer类的组件化设计，模型开发效率提升体现在能够快速实验和迭代新特性。开...</td>\n",
       "      <td>['添加新的特性将变得更加容易。¶\\n现在我们只需要为新的特征开发一个Keras Layer...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx                             input  \\\n",
       "0    0                 组件化如何简化模型开发并提高效率？   \n",
       "1    1  如何通过Keras Layer类的组件化设计提高模型开发的效率？   \n",
       "\n",
       "                                              output  \\\n",
       "0  组件化通过模块化和配置化的方法简化了模型开发流程。它允许开发者专注于设计独特的子模块（组件）...   \n",
       "1  通过Keras Layer类的组件化设计，模型开发效率提升体现在能够快速实验和迭代新特性。开...   \n",
       "\n",
       "                                           reference  \n",
       "0  ['为何需要组件化¶\\n1. 依靠动态可插拔的公共组件，方便为现有模型添加新特性。¶\\n过去...  \n",
       "1  ['添加新的特性将变得更加容易。¶\\n现在我们只需要为新的特征开发一个Keras Layer...  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_df = pd.DataFrame(retrieval_data)\n",
    "response_df = pd.DataFrame(llm_data)\n",
    "response_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4944bd4f-bece-4cc4-9469-fc01e66449b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the openai api key exists in env\n",
    "if not (openai_api_key := os.getenv(\"OPENAI_API_KEY\")):\n",
    "    openai_api_key = getpass(\"Enter your OpenAI API key: \")\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628e9f11-4cb9-4e62-bf1a-9035777d3534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use OpenAI model for evals\n",
    "eval_model = OpenAIModel(model=\"gpt-3.5-turbo\", api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb75d65-fa8d-4cfc-9b3d-f6f489114970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LLM evaluators with eval model and prompt templates\n",
    "faithfulness_evaluator = LLMEvaluator(\n",
    "    eval_model, DefaultPromptTemplateCN.FAITHFULNESS_PROMPT_TEMPLATE\n",
    ")\n",
    "correctness_evaluator = LLMEvaluator(\n",
    "    eval_model, DefaultPromptTemplateCN.RAG_CORRECTNESS_PROMPT_TEMPLATE\n",
    ")\n",
    "relevance_evaluator = LLMEvaluator(\n",
    "    eval_model, DefaultPromptTemplateCN.RETRIEVER_RELEVANCE_PROMPT_TEMPLATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920c292d-46fe-4571-8fde-a57cc2c61d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the event loop with nest_asyncio to improve efficiency\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60346f7-e1d4-41ad-a941-9f2760f52e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness_eval_df:\n",
      "   label  score                                        explanation  \\\n",
      "0    事实      1  根据参考文本，答案中提到的EasyRec支持的输入数据类型和提供的模型是事实，与参考文本中的...   \n",
      "1    事实      1  根据参考文本，EasyRec支持在MaxCompute、数据科学平台、DLC和本地环境上运行...   \n",
      "2    事实      1  根据参考文本，EasyRec实现了常见推荐任务中的机器学习模型，包括候选生成、评分和多任务学...   \n",
      "3    事实      1  根据参考文本，答案中提到的EasyRec如何提高生成高性能模型的效率的方法都是基于参考文本中...   \n",
      "4    事实      1  根据参考文本内容，答案中提到的组件化的优势和EasyRec框架的特点都是基于参考文本中提供的...   \n",
      "\n",
      "    metric_name eval_type  \n",
      "0  faithfulness       llm  \n",
      "1  faithfulness       llm  \n",
      "2  faithfulness       llm  \n",
      "3  faithfulness       llm  \n",
      "4  faithfulness       llm  \n",
      "\n",
      "\n",
      "correctness_eval_df:\n",
      "   label  score                                        explanation  \\\n",
      "0   不正确      0  参考文本提到EasyRec支持MaxCompute表、HDFS文件、操作系统文件、卡夫卡流和...   \n",
      "1    正确      1  参考文本提到EasyRec支持在MaxCompute、数据科学平台、DLC、本地环境上运行，...   \n",
      "2    正确      1  The answer correctly identifies the machine le...   \n",
      "3    正确      1  The answer correctly explains how EasyRec impr...   \n",
      "4    正确      1   根据提供的参考文本，逐步比对问题和答案之间的内容，确保答案涵盖了问题的所有要点并提供了详细解释。   \n",
      "\n",
      "       metric_name eval_type  \n",
      "0  rag_correctness       llm  \n",
      "1  rag_correctness       llm  \n",
      "2  rag_correctness       llm  \n",
      "3  rag_correctness       llm  \n",
      "4  rag_correctness       llm  \n"
     ]
    }
   ],
   "source": [
    "# Evaluate faithfulness and correctness\n",
    "faithfulness_eval_df, correctness_eval_df = run_evals(\n",
    "    dataframe=response_eval_df,\n",
    "    evaluators=[faithfulness_evaluator, correctness_evaluator],\n",
    "    provide_explanation=True,\n",
    ")\n",
    "print(f\"faithfulness_eval_df:\\n {faithfulness_eval_df}\")\n",
    "print(f\"\\n\\ncorrectness_eval_df:\\n {correctness_eval_df}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2124c5dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faithfulness_eval_df[\"score\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad18d45b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'faithfulness_score': 1,\n",
       "  'faithfulness_reason': '根据参考文本，答案中提到的EasyRec支持的输入数据类型和提供的模型是事实，与参考文本中的信息一致。因此，答案是\"事实\"。',\n",
       "  'correctness_score': 0,\n",
       "  'correctness_reason': '参考文本提到EasyRec支持MaxCompute表、HDFS文件、操作系统文件、卡夫卡流和本地CSV作为输入数据类型，但答案只提到了MaxCompute表、HDFS文件、操作系统文件、Kafka流和本地CSV，漏掉了卡夫卡流一项。因此，答案只回答了部分问题，不完整，应为\"不正确\"。'},\n",
       " {'faithfulness_score': 1,\n",
       "  'faithfulness_reason': '根据参考文本，EasyRec支持在MaxCompute、数据科学平台、DLC和本地环境上运行。此外，它还支持不同版本的TensorFlow，包括TF1.12-1.15、TF2.x和PAI-TF。因此，答案中提到的平台和TensorFlow版本都是基于参考文本中的信息，没有提供虚假信息。因此，答案是事实。',\n",
       "  'correctness_score': 1,\n",
       "  'correctness_reason': '参考文本提到EasyRec支持在MaxCompute、数据科学平台、DLC、本地环境上运行，并且可以在不同的TensorFlow版本上运行。答案中列出了这些平台和TensorFlow版本，说明了EasyRec具有广泛的平台兼容性。因此，答案完整回答了问题并提供了详细信息，可以判断为\"正确\"。'},\n",
       " {'faithfulness_score': 1,\n",
       "  'faithfulness_reason': '根据参考文本，EasyRec实现了常见推荐任务中的机器学习模型，包括候选生成、评分和多任务学习。参考文本中也提到了具体的模型实例，如DSSM、MIND、DropoutNet等，这些模型并不完全对应于上述三大类推荐任务，而是基于这些基础任务之上构建的具体实现或变种。因此，答案中提到的模型类型和相关信息都可以在参考文本中找到支持，没有提供虚假信息。因此，答案是“事实”。',\n",
       "  'correctness_score': 1,\n",
       "  'correctness_reason': 'The answer correctly identifies the machine learning models implemented by EasyRec for common recommendation tasks, including candidate generation, scoring, and multi-task learning. It also mentions specific models like DSSM, MIND, and DropoutNet as examples. The answer provides a comprehensive and accurate response to the question based on the reference text.'},\n",
       " {'faithfulness_score': 1,\n",
       "  'faithfulness_reason': '根据参考文本，答案中提到的EasyRec如何提高生成高性能模型的效率的方法都是基于参考文本中提到的事实信息，包括简单的配置、超参数调整、多样的输入数据处理能力、高效的特征生成、多种模型支持和易于定制化。因此，答案是“事实”。',\n",
       "  'correctness_score': 1,\n",
       "  'correctness_reason': 'The answer correctly explains how EasyRec improves the efficiency of generating high-performance models by highlighting key aspects such as simple configuration, hyperparameter tuning, diverse input data processing capabilities, efficient feature generation, support for multiple models, and ease of customization. The answer provides a comprehensive overview of how EasyRec enhances the efficiency of generating high-performance models.'},\n",
       " {'faithfulness_score': 1,\n",
       "  'faithfulness_reason': '根据参考文本内容，答案中提到的组件化的优势和EasyRec框架的特点都是基于参考文本中提供的信息，没有虚构信息。因此，答案是事实。',\n",
       "  'correctness_score': 1,\n",
       "  'correctness_reason': '根据提供的参考文本，逐步比对问题和答案之间的内容，确保答案涵盖了问题的所有要点并提供了详细解释。'}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses = [\n",
    "    {\n",
    "        \"faithfulness_score\": f_s,\n",
    "        \"faithfulness_reason\": f_e,\n",
    "        \"correctness_score\": c_s,\n",
    "        \"correctness_reason\": c_e,\n",
    "    }\n",
    "    for f_s, f_e, c_s, c_e in zip(\n",
    "        faithfulness_eval_df[\"score\"].tolist(),\n",
    "        faithfulness_eval_df[\"explanation\"].tolist(),\n",
    "        correctness_eval_df[\"score\"].tolist(),\n",
    "        correctness_eval_df[\"explanation\"].tolist(),\n",
    "    )\n",
    "]\n",
    "responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0092be9-f791-4393-b9a3-94f2fc22b8ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relevance_eval_df:\n",
      "    idx     label   score                                        explanation  \\\n",
      "0    0  [相关, 相关]  [1, 1]  [参考文本提到组件化简化模型开发并提高效率，描述了如何添加新特性并提高开发效率，因此与问题相...   \n",
      "1    1  [相关, 相关]  [1, 1]  [参考文本提到通过重组已有组件实现“搭积木”式新模型开发，这与问题中询问如何通过Keras ...   \n",
      "\n",
      "                                         document_id  \\\n",
      "0  [13bed26b44134f96812e4f758bfa1b00b498c104ac42e...   \n",
      "1  [182bca8f8d785f74c7173ab47359a663164c408fe857c...   \n",
      "\n",
      "                               document_score          metric_name eval_type  \n",
      "0  [0.09999999999999999, 0.09836065573770493]  retriever_relevance  retrieve  \n",
      "1  [0.09918032786885246, 0.09918032786885246]  retriever_relevance  retrieve  \n"
     ]
    }
   ],
   "source": [
    "# Evaluate retrieval relevance\n",
    "relevance_eval_df = run_evals(\n",
    "    dataframe=retrieval_df,\n",
    "    evaluators=[relevance_evaluator],\n",
    "    provide_explanation=True,\n",
    ")[0]\n",
    "print(f\"relevance_eval_df:\\n {relevance_eval_df}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb8cfaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'chatcmpl-53c849cb-daeb-9c02-9b9d-4e803b0a6cff', 'choices': [{'finish_reason': 'tool_calls', 'index': 0, 'logprobs': None, 'message': {'content': '', 'refusal': None, 'role': 'assistant', 'function_call': None, 'tool_calls': [{'id': 'call_6e649ed77cbc4ea295fdf6', 'function': {'arguments': '', 'name': 'record_response\\n\": {\"'}, 'type': 'function', 'index': 0}]}}], 'created': 1729246227, 'model': 'qwen-max', 'object': 'chat.completion', 'service_tier': None, 'system_fingerprint': None, 'usage': {'completion_tokens': 5, 'prompt_tokens': 1066, 'total_tokens': 1071}}\n"
     ]
    }
   ],
   "source": [
    "kwargs = {\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": '\\n    在此任务中，您将看到一个查询、参考文本和答案。答案是根据参考文本生成问题。答案可能包含虚假信息，您\\n    必须使用参考文本来确定问题的答案是否包含虚假信息，如果答案是事实的幻觉。您的目标是确定参考文本是否\\n    包含事实信息，并非幻觉。本文中的“幻觉”是指答案不是基于参考文本或假设的信息不可用参考文本。\\n\\n        [开始数据]\\n        **********\\n        [查询]：机器学习PAI是什么？\\n        **********\\n        [参考文字]：[\\'机器学习PAI（Platform of Artificial Intelligence）是阿里云人工智能平台，提供一站式的机器学习解决方案。本文为您介绍什么是机器学习PAI。\\\\n\\\\n什么是机器学习\\\\n机器学习是指机器通过统计学算法，对大量历史数据进行学习，进而利用生成的经验模型指导业务。目前机器学习主要应用在以下场景：\\\\n营销类场景：商品推荐、用户群体画像或广告精准投放。\\\\n金融类场景：贷款发放预测、金融风险控制、股票走势预测或黄金价格预测。\\\\n社交网络服务关系挖掘场景：微博粉丝领袖分析或社交关系链分析。\\\\n文本类场景：新闻分类、关键词提取、文章摘要或文本内容分析。\\\\n非结构化数据处理场景：图片分类或图片文本内容提取。\\\\n其它各类预测场景：降雨预测或足球比赛结果预测。\\\\n机器学习包括传统机器学习和深度学习。传统机器学习分为以下几类：\\\\n有监督学习（Supervised Learning）：每个样本都有对应的期望值，通过搭建模型，实现从输入特征向量到目标值的映射。例如解决回归和分类问题。\\\\n无监督学习（Unsupervised Learning）：所有样本没有目标值，期望从数据本身发现一些潜在规律。例如解决聚类问题。\\', \\'其它各类预测场景：降雨预测或足球比赛结果预测。\\\\n机器学习包括传统机器学习和深度学习。传统机器学习分为以下几类：\\\\n有监督学习（Supervised Learning）：每个样本都有对应的期望值，通过搭建模型，实现从输入特征向量到目标值的映射。例如解决回归和分类问题。\\\\n无监督学习（Unsupervised Learning）：所有样本没有目标值，期望从数据本身发现一些潜在规律。例如解决聚类问题。\\\\n增强学习（Reinforcement Learning）：相对比较复杂，系统和外界环境不断交互，根据外界反馈决定自身行为，达到目标最优化。例如阿尔法围棋和无人驾驶。\\']\\n        **********\\n        [答案]：机器学习PAI（Platform of Artificial Intelligence）是阿里云提供的一站式机器学习解决方案。它旨在帮助用户通过使用统计学算法对大量历史数据进行学习，进而利用生成的经验模型来指导业务。机器学习PAI支持多种应用场景，包括但不限于营销类场景、金融类场景、社交网络服务关系挖掘场景、文本类场景以及非结构化数据处理场景等。此外，机器学习PAI涵盖了传统机器学习和深度学习技术，其中传统机器学习又细分为有监督学习、无监督学习和增强学习等多种类型。\\n        **********\\n        [数据结束]\\n\\n        根据查询和参考文本，上述答案是事实还是幻觉？\\n\\n    请仔细阅读查询、参考文本和答案，然后逐步写出说明如何确定答案是“事实”还是“幻觉”。简单地避免\\n    一开始就说出正确答案。您的回复标签应该是一个单词：要么“事实”或“幻觉”，并且不应包含任何其他\\n    文本或字符。 “产生幻觉”表示答案向基于查询的查询提供了事实上不准确的信息参考文本。 “事实”表\\n    明问题的答案相对于事实是正确的参考文本，不包含虚构信息。\\n\\n    仔细思考一会，然后给出你的结论。你返回的内容是一个json数据结构，其中包含以下字段：\"label\"，\"reason\"。\\n    返回格式如下：{\"label\":\"<标签>\", \"reason\":\"<理由>\"}\\n    ',\n",
    "        }\n",
    "    ],\n",
    "    \"model\": \"qwen-max\",\n",
    "    \"temperature\": 0.0,\n",
    "    \"max_tokens\": 256,\n",
    "    \"frequency_penalty\": 0,\n",
    "    \"presence_penalty\": 0,\n",
    "    \"top_p\": 0.99,\n",
    "    \"n\": 1,\n",
    "    \"timeout\": None,\n",
    "    \"tools\": [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"record_response\",\n",
    "                \"description\": \"A function to record your response.\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"explanation\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"Explanation of the reasoning for your response.\",\n",
    "                        },\n",
    "                        \"response\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"Your response.\",\n",
    "                            \"enum\": [\"事实\", \"幻觉\"],\n",
    "                        },\n",
    "                    },\n",
    "                    \"required\": [\"explanation\", \"response\"],\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "    ],\n",
    "    \"tool_choice\": {\"type\": \"function\", \"function\": {\"name\": \"record_response\"}},\n",
    "    \"response_format\": {\"type\": \"json_object\"},\n",
    "}\n",
    "\n",
    "import openai\n",
    "\n",
    "_client = openai.OpenAI(\n",
    "    api_key=\"sk-499ae44046ee48dfbcb38b6a47045b05\",\n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    ")\n",
    "\n",
    "res = _client.chat.completions.create(**kwargs).model_dump()\n",
    "\n",
    "print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

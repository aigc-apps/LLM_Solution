{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/feiyue/huggingface/sentence_transformers/bge-small-zh-v1.5'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "model_dir = \"/Users/feiyue/huggingface/sentence_transformers\"\n",
    "model_name = \"bge-small-zh-v1.5\"\n",
    "\n",
    "model_path = os.path.join(model_dir, model_name)\n",
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "embed_model = HuggingFaceEmbedding(model_name=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i in range(5000):\n",
    "    embeddings = embed_model.get_text_embedding(\"It is raining cats and dogs here!\")\n",
    "# embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class HuggingFaceEmbedding in module llama_index.embeddings.huggingface.base:\n",
      "\n",
      "class HuggingFaceEmbedding(llama_index.core.base.embeddings.base.BaseEmbedding)\n",
      " |  HuggingFaceEmbedding(model_name: Optional[str] = None, tokenizer_name: Optional[str] = None, pooling: Union[str, llama_index.embeddings.huggingface.pooling.Pooling] = 'cls', max_length: Optional[int] = None, query_instruction: Optional[str] = None, text_instruction: Optional[str] = None, normalize: bool = True, model: Optional[Any] = None, tokenizer: Optional[Any] = None, embed_batch_size: int = 10, cache_folder: Optional[str] = None, trust_remote_code: bool = False, device: Optional[str] = None, callback_manager: Optional[llama_index.core.callbacks.base.CallbackManager] = None, safe_serialization: Optional[bool] = None) -> None\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      HuggingFaceEmbedding\n",
      " |      llama_index.core.base.embeddings.base.BaseEmbedding\n",
      " |      llama_index.core.schema.TransformComponent\n",
      " |      llama_index.core.schema.BaseComponent\n",
      " |      pydantic.v1.main.BaseModel\n",
      " |      pydantic.v1.utils.Representation\n",
      " |      llama_index.core.instrumentation.DispatcherSpanMixin\n",
      " |      abc.ABC\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, model_name: Optional[str] = None, tokenizer_name: Optional[str] = None, pooling: Union[str, llama_index.embeddings.huggingface.pooling.Pooling] = 'cls', max_length: Optional[int] = None, query_instruction: Optional[str] = None, text_instruction: Optional[str] = None, normalize: bool = True, model: Optional[Any] = None, tokenizer: Optional[Any] = None, embed_batch_size: int = 10, cache_folder: Optional[str] = None, trust_remote_code: bool = False, device: Optional[str] = None, callback_manager: Optional[llama_index.core.callbacks.base.CallbackManager] = None, safe_serialization: Optional[bool] = None)\n",
      " |      Create a new model by parsing and validating input data from keyword arguments.\n",
      " |      \n",
      " |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  class_name() -> str from pydantic.v1.main.ModelMetaclass\n",
      " |      Get the class name, used as a unique ID in serialization.\n",
      " |      \n",
      " |      This provides a key that makes serialization robust against actual class\n",
      " |      name changes.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  __annotations__ = {'_device': <class 'str'>, '_model': typing.Any, '_t...\n",
      " |  \n",
      " |  __class_vars__ = set()\n",
      " |  \n",
      " |  __config__ = <class 'pydantic.v1.config.Config'>\n",
      " |  \n",
      " |  __custom_root_type__ = False\n",
      " |  \n",
      " |  __exclude_fields__ = {'callback_manager': True}\n",
      " |  \n",
      " |  __fields__ = {'cache_folder': ModelField(name='cache_folder', type=Opt...\n",
      " |  \n",
      " |  __hash__ = None\n",
      " |  \n",
      " |  __include_fields__ = None\n",
      " |  \n",
      " |  __post_root_validators__ = []\n",
      " |  \n",
      " |  __pre_root_validators__ = []\n",
      " |  \n",
      " |  __private_attributes__ = {'_device': ModelPrivateAttr(default=Pydantic...\n",
      " |  \n",
      " |  __schema_cache__ = {}\n",
      " |  \n",
      " |  __signature__ = <Signature (model_name: Optional[str] = None, to...fe_...\n",
      " |  \n",
      " |  __validators__ = {'callback_manager': [<pydantic.v1.class_validators.V...\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from llama_index.core.base.embeddings.base.BaseEmbedding:\n",
      " |  \n",
      " |  __call__(self, nodes: List[llama_index.core.schema.BaseNode], **kwargs: Any) -> List[llama_index.core.schema.BaseNode]\n",
      " |  \n",
      " |  async acall(self, nodes: List[llama_index.core.schema.BaseNode], **kwargs: Any) -> List[llama_index.core.schema.BaseNode]\n",
      " |      Async transform nodes.\n",
      " |  \n",
      " |  async aget_agg_embedding_from_queries(self, queries: List[str], agg_fn: Optional[Callable[..., List[float]]] = None) -> List[float]\n",
      " |      Async get aggregated embedding from multiple queries.\n",
      " |  \n",
      " |  async aget_query_embedding(self, query: str) -> List[float]\n",
      " |      Get query embedding.\n",
      " |  \n",
      " |  async aget_text_embedding(self, text: str) -> List[float]\n",
      " |      Async get text embedding.\n",
      " |  \n",
      " |  async aget_text_embedding_batch(self, texts: List[str], show_progress: bool = False) -> List[List[float]]\n",
      " |      Asynchronously get a list of text embeddings, with batching.\n",
      " |  \n",
      " |  get_agg_embedding_from_queries(self, queries: List[str], agg_fn: Optional[Callable[..., List[float]]] = None) -> List[float]\n",
      " |      Get aggregated embedding from multiple queries.\n",
      " |  \n",
      " |  get_query_embedding(self, query: str) -> List[float]\n",
      " |      Embed the input query.\n",
      " |      \n",
      " |      When embedding a query, depending on the model, a special instruction\n",
      " |      can be prepended to the raw query string. For example, \"Represent the\n",
      " |      question for retrieving supporting documents: \". If you're curious,\n",
      " |      other examples of predefined instructions can be found in\n",
      " |      embeddings/huggingface_utils.py.\n",
      " |  \n",
      " |  get_text_embedding(self, text: str) -> List[float]\n",
      " |      Embed the input text.\n",
      " |      \n",
      " |      When embedding text, depending on the model, a special instruction\n",
      " |      can be prepended to the raw text string. For example, \"Represent the\n",
      " |      document for retrieval: \". If you're curious, other examples of\n",
      " |      predefined instructions can be found in embeddings/huggingface_utils.py.\n",
      " |  \n",
      " |  get_text_embedding_batch(self, texts: List[str], show_progress: bool = False, **kwargs: Any) -> List[List[float]]\n",
      " |      Get a list of text embeddings, with batching.\n",
      " |  \n",
      " |  similarity(self, embedding1: List[float], embedding2: List[float], mode: llama_index.core.base.embeddings.base.SimilarityMode = <SimilarityMode.DEFAULT: 'cosine'>) -> float\n",
      " |      Get embedding similarity.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from llama_index.core.base.embeddings.base.BaseEmbedding:\n",
      " |  \n",
      " |  Config = <class 'llama_index.core.base.embeddings.base.BaseEmbedding.C...\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from llama_index.core.schema.TransformComponent:\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from llama_index.core.schema.BaseComponent:\n",
      " |  \n",
      " |  __getstate__(self) -> Dict[str, Any]\n",
      " |  \n",
      " |  __setstate__(self, state: Dict[str, Any]) -> None\n",
      " |  \n",
      " |  dict(self, **kwargs: Any) -> Dict[str, Any]\n",
      " |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      " |  \n",
      " |  json(self, **kwargs: Any) -> str\n",
      " |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      " |      \n",
      " |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      " |  \n",
      " |  to_dict(self, **kwargs: Any) -> Dict[str, Any]\n",
      " |  \n",
      " |  to_json(self, **kwargs: Any) -> str\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from llama_index.core.schema.BaseComponent:\n",
      " |  \n",
      " |  from_dict(data: Dict[str, Any], **kwargs: Any) -> typing_extensions.Self from pydantic.v1.main.ModelMetaclass\n",
      " |      # TODO: return type here not supported by current mypy version\n",
      " |  \n",
      " |  from_json(data_str: str, **kwargs: Any) -> typing_extensions.Self from pydantic.v1.main.ModelMetaclass\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pydantic.v1.main.BaseModel:\n",
      " |  \n",
      " |  __eq__(self, other: Any) -> bool\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __iter__(self) -> 'TupleGenerator'\n",
      " |      so `dict(model)` works\n",
      " |  \n",
      " |  __repr_args__(self) -> 'ReprArgs'\n",
      " |      Returns the attributes to show in __str__, __repr__, and __pretty__ this is generally overridden.\n",
      " |      \n",
      " |      Can either return:\n",
      " |      * name - value pairs, e.g.: `[('foo_name', 'foo'), ('bar_name', ['b', 'a', 'r'])]`\n",
      " |      * or, just values, e.g.: `[(None, 'foo'), (None, ['b', 'a', 'r'])]`\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Implement setattr(self, name, value).\n",
      " |  \n",
      " |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      " |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      " |      \n",
      " |      :param include: fields to include in new model\n",
      " |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      " |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      " |          the new model: you should trust this data\n",
      " |      :param deep: set to `True` to make a deep copy of the model\n",
      " |      :return: new model instance\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from pydantic.v1.main.BaseModel:\n",
      " |  \n",
      " |  __get_validators__() -> 'CallableGenerator' from pydantic.v1.main.ModelMetaclass\n",
      " |  \n",
      " |  __try_update_forward_refs__(**localns: Any) -> None from pydantic.v1.main.ModelMetaclass\n",
      " |      Same as update_forward_refs but will not raise exception\n",
      " |      when forward references are not defined.\n",
      " |  \n",
      " |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from pydantic.v1.main.ModelMetaclass\n",
      " |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      " |      Default values are respected, but no other validation is performed.\n",
      " |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      " |  \n",
      " |  from_orm(obj: Any) -> 'Model' from pydantic.v1.main.ModelMetaclass\n",
      " |  \n",
      " |  parse_file(path: Union[str, pathlib.Path], *, content_type: str = None, encoding: str = 'utf8', proto: pydantic.v1.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.v1.main.ModelMetaclass\n",
      " |  \n",
      " |  parse_obj(obj: Any) -> 'Model' from pydantic.v1.main.ModelMetaclass\n",
      " |  \n",
      " |  parse_raw(b: Union[str, bytes], *, content_type: str = None, encoding: str = 'utf8', proto: pydantic.v1.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.v1.main.ModelMetaclass\n",
      " |  \n",
      " |  schema(by_alias: bool = True, ref_template: str = '#/definitions/{model}') -> 'DictStrAny' from pydantic.v1.main.ModelMetaclass\n",
      " |  \n",
      " |  schema_json(*, by_alias: bool = True, ref_template: str = '#/definitions/{model}', **dumps_kwargs: Any) -> str from pydantic.v1.main.ModelMetaclass\n",
      " |  \n",
      " |  update_forward_refs(**localns: Any) -> None from pydantic.v1.main.ModelMetaclass\n",
      " |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      " |  \n",
      " |  validate(value: Any) -> 'Model' from pydantic.v1.main.ModelMetaclass\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pydantic.v1.main.BaseModel:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __fields_set__\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pydantic.v1.utils.Representation:\n",
      " |  \n",
      " |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      " |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      " |  \n",
      " |  __repr__(self) -> str\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __repr_name__(self) -> str\n",
      " |      Name of the instance's class, used in __repr__.\n",
      " |  \n",
      " |  __repr_str__(self, join_str: str) -> str\n",
      " |  \n",
      " |  __rich_repr__(self) -> 'RichReprResult'\n",
      " |      Get fields for Rich library\n",
      " |  \n",
      " |  __str__(self) -> str\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from llama_index.core.instrumentation.DispatcherSpanMixin:\n",
      " |  \n",
      " |  __init_subclass__(**kwargs: Any) -> None from pydantic.v1.main.ModelMetaclass\n",
      " |      This method is called when a class is subclassed.\n",
      " |      \n",
      " |      The default implementation does nothing. It may be\n",
      " |      overridden to extend subclasses.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(HuggingFaceEmbedding)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "onnx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

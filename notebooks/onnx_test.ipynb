{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/llm/feiyue/miniconda3/envs/onnx/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/huggingface/sentence_transformers/bge-small-zh-v1.5'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from optimum.onnxruntime import ORTModelForFeatureExtraction\n",
    "from transformers import AutoTokenizer\n",
    "from pathlib import Path\n",
    "from transformers import Pipeline\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import os\n",
    "\n",
    "model_dir = \"/huggingface/sentence_transformers\"\n",
    "model_name = \"bge-small-zh-v1.5\"\n",
    "\n",
    "model_path = os.path.join(model_dir, model_name)\n",
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The argument `from_transformers` is deprecated, and will be removed in optimum 2.0.  Use `export` instead\n",
      "Framework not specified. Using pt to export the model.\n",
      "Using the export variant default. Available variants are:\n",
      "    - default: The default ONNX variant.\n",
      "\n",
      "***** Exporting submodel 1/1: BertModel *****\n",
      "Using framework PyTorch: 2.2.2+cu121\n",
      "Overriding 1 configuration item(s)\n",
      "\t- use_cache -> False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/tmpmtal4pd2/model.onnx\n",
      "False\n",
      "<onnxruntime.capi.onnxruntime_pybind11_state.SessionOptions object at 0x7f2ec2c42c70>\n",
      "[<onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7f2ec2c42c70>, <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7f2ec3318f30>, <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7f2ec3319070>]\n",
      "[<onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7f2ec2c42c70>]\n",
      "/tmp/tmpmtal4pd2/model.onnx\n",
      "False\n",
      "<onnxruntime.capi.onnxruntime_pybind11_state.SessionOptions object at 0x7f2ec21ad530>\n",
      "[<onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7f2ec21ad530>, <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7f2ec21ae2f0>, <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7f2ec21ad2b0>]\n",
      "[<onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7f2ec21ad530>]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./tmp/bge_onnx/tokenizer_config.json',\n",
       " './tmp/bge_onnx/special_tokens_map.json',\n",
       " './tmp/bge_onnx/vocab.txt',\n",
       " './tmp/bge_onnx/added_tokens.json',\n",
       " './tmp/bge_onnx/tokenizer.json')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onnx_path = \"./tmp/bge_onnx\"\n",
    "# load vanilla transformers and convert to onnx\n",
    "model = ORTModelForFeatureExtraction.from_pretrained(model_path, from_transformers=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# save onnx checkpoint and tokenizer\n",
    "model.save_pretrained(onnx_path)\n",
    "tokenizer.save_pretrained(onnx_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./tmp/bge_onnx/model.onnx\n",
      "False\n",
      "<onnxruntime.capi.onnxruntime_pybind11_state.SessionOptions object at 0x7f301bf6f130>\n",
      "[<onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7f301bf6f130>, <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7f2eb6d044b0>, <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7f2ebc744070>]\n",
      "[<onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7f2eb6c7e230>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0;93m2024-07-11 16:30:22.993250331 [W:onnxruntime:, transformer_memcpy.cc:74 ApplyImpl] 4 Memcpy nodes are added to the graph main_graph for CUDAExecutionProvider. It might have negative impact on performance (including unable to run CUDA graph). Set session_options.log_severity_level=1 to see the detail logs before this message.\u001b[m\n",
      "\u001b[0;93m2024-07-11 16:30:22.994253030 [W:onnxruntime:, session_state.cc:1166 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.\u001b[m\n",
      "\u001b[0;93m2024-07-11 16:30:22.994262661 [W:onnxruntime:, session_state.cc:1168 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.\u001b[m\n",
      "\u001b[0;93m2024-07-11 16:30:23.029039355 [W:onnxruntime:, inference_session.cc:1978 Initialize] Serializing optimized model with Graph Optimization level greater than ORT_ENABLE_EXTENDED and the NchwcTransformer enabled. The generated model may contain hardware specific optimizations, and should only be used in the same environment the model was optimized in.\u001b[m\n"
     ]
    }
   ],
   "source": [
    "from onnxruntime.transformers import optimizer\n",
    "\n",
    "optimized_model = optimizer.optimize_model(\n",
    "    \"./tmp/bge_onnx/model.onnx\",\n",
    "    model_type=\"bert\",\n",
    "    num_heads=12,\n",
    "    hidden_size=768,\n",
    "    opt_level=99,\n",
    "    use_gpu=True,\n",
    "    only_onnxruntime=True,\n",
    ")\n",
    "optimized_model.convert_float_to_float16()\n",
    "\n",
    "optimized_model.save_model_to_file(\"./tmp/bge_onnx/model_fp16.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./tmp/bge_onnx/model.onnx\n",
      "False\n",
      "<onnxruntime.capi.onnxruntime_pybind11_state.SessionOptions object at 0x7fd572501c70>\n",
      "[<onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7fd572501c70>, <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7fd572501cb0>, <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7fd5725026f0>]\n",
      "[<onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7fd572501c70>]\n",
      "\u001b[0;93m2024-07-11 16:30:32.291283074 [W:onnxruntime:, transformer_memcpy.cc:74 ApplyImpl] 10 Memcpy nodes are added to the graph main_graph for CUDAExecutionProvider. It might have negative impact on performance (including unable to run CUDA graph). Set session_options.log_severity_level=1 to see the detail logs before this message.\u001b[m\n",
      "./tmp/bge_onnx/model_fp16.onnx\n",
      "False\n",
      "<onnxruntime.capi.onnxruntime_pybind11_state.SessionOptions object at 0x7fd5725026f0>\n",
      "[<onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7fd5725026f0>, <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7fd572501c70>, <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7fd572501cb0>]\n",
      "[<onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7fd5725026f0>]\n",
      "\u001b[0;93m2024-07-11 16:30:33.122091241 [W:onnxruntime:, transformer_memcpy.cc:74 ApplyImpl] 8 Memcpy nodes are added to the graph main_graph for CUDAExecutionProvider. It might have negative impact on performance (including unable to run CUDA graph). Set session_options.log_severity_level=1 to see the detail logs before this message.\u001b[m\n",
      "WARNING: 500 out of 500 results NOT passed for thresholds (rtol=0.001, atol=0.0001).\n",
      "maximum absolute difference=0.0088653564453125\n"
     ]
    }
   ],
   "source": [
    "!python -m onnxruntime.transformers.compare_bert_results --use_gpu  --baseline_model ./tmp/bge_onnx/model.onnx --optimized_model ./tmp/bge_onnx/model_fp16.onnx --batch_size 1 --sequence_length 128 --samples 500\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test setting TestSetting(batch_size=1, sequence_length=512, test_cases=10, test_times=100, use_gpu=True, use_io_binding=True, provider=None, intra_op_num_threads=None, seed=3, verbose=False, log_severity=2, average_sequence_length=512, random_sequence_length=False)\n",
      "Generating 10 samples for batch_size=1 sequence_length=512\n",
      "./tmp/bge_onnx/model_fp16.onnx\n",
      "False\n",
      "<onnxruntime.capi.onnxruntime_pybind11_state.SessionOptions object at 0x7f7c92b3dcf0>\n",
      "[<onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7f7c92b3dcf0>, <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7f7c912a9d70>, <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7f7c91390ef0>]\n",
      "[<onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7f7c92b3dcf0>]\n",
      "\u001b[0;93m2024-07-11 16:31:05.582628583 [W:onnxruntime:, transformer_memcpy.cc:74 ApplyImpl] 8 Memcpy nodes are added to the graph main_graph for CUDAExecutionProvider. It might have negative impact on performance (including unable to run CUDA graph). Set session_options.log_severity_level=1 to see the detail logs before this message.\u001b[m\n",
      "Running test: model=model_fp16.onnx,graph_optimization_level=ENABLE_ALL,intra_op_num_threads=32,batch_size=1,sequence_length=512,test_cases=10,test_times=100,use_gpu=True,use_io_binding=True,average_sequence_length=512,random_sequence_length=False\n",
      "Average latency = 0.94 ms, Throughput = 1067.01 QPS\n",
      "./tmp/bge_onnx/model_fp16.onnx\n",
      "False\n",
      "<onnxruntime.capi.onnxruntime_pybind11_state.SessionOptions object at 0x7f7c92b3dcf0>\n",
      "[<onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7f7c92b3dcf0>, <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7f7c912a9d70>, <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7f7c91390ef0>]\n",
      "[<onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7f7c92b3dcf0>]\n",
      "\u001b[0;93m2024-07-11 16:31:09.468356000 [W:onnxruntime:, transformer_memcpy.cc:74 ApplyImpl] 8 Memcpy nodes are added to the graph main_graph for CUDAExecutionProvider. It might have negative impact on performance (including unable to run CUDA graph). Set session_options.log_severity_level=1 to see the detail logs before this message.\u001b[m\n",
      "Running test: model=model_fp16.onnx,graph_optimization_level=ENABLE_ALL,intra_op_num_threads=16,batch_size=1,sequence_length=512,test_cases=10,test_times=100,use_gpu=True,use_io_binding=True,average_sequence_length=512,random_sequence_length=False\n",
      "Average latency = 0.94 ms, Throughput = 1059.63 QPS\n",
      "./tmp/bge_onnx/model_fp16.onnx\n",
      "False\n",
      "<onnxruntime.capi.onnxruntime_pybind11_state.SessionOptions object at 0x7f7c92b3dcf0>\n",
      "[<onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7f7c92b3dcf0>, <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7f7c912a9d70>, <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7f7c91390ef0>]\n",
      "[<onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7f7c92b3dcf0>]\n",
      "\u001b[0;93m2024-07-11 16:31:13.353467498 [W:onnxruntime:, transformer_memcpy.cc:74 ApplyImpl] 8 Memcpy nodes are added to the graph main_graph for CUDAExecutionProvider. It might have negative impact on performance (including unable to run CUDA graph). Set session_options.log_severity_level=1 to see the detail logs before this message.\u001b[m\n",
      "Running test: model=model_fp16.onnx,graph_optimization_level=ENABLE_ALL,intra_op_num_threads=15,batch_size=1,sequence_length=512,test_cases=10,test_times=100,use_gpu=True,use_io_binding=True,average_sequence_length=512,random_sequence_length=False\n",
      "Average latency = 0.94 ms, Throughput = 1062.58 QPS\n",
      "./tmp/bge_onnx/model_fp16.onnx\n",
      "False\n",
      "<onnxruntime.capi.onnxruntime_pybind11_state.SessionOptions object at 0x7f7c92b3dcf0>\n",
      "[<onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7f7c92b3dcf0>, <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7f7c912a9d70>, <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7f7d430f95f0>]\n",
      "[<onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7f7c92b3dcf0>]\n",
      "\u001b[0;93m2024-07-11 16:31:17.240251383 [W:onnxruntime:, transformer_memcpy.cc:74 ApplyImpl] 8 Memcpy nodes are added to the graph main_graph for CUDAExecutionProvider. It might have negative impact on performance (including unable to run CUDA graph). Set session_options.log_severity_level=1 to see the detail logs before this message.\u001b[m\n",
      "Running test: model=model_fp16.onnx,graph_optimization_level=ENABLE_ALL,intra_op_num_threads=14,batch_size=1,sequence_length=512,test_cases=10,test_times=100,use_gpu=True,use_io_binding=True,average_sequence_length=512,random_sequence_length=False\n",
      "Average latency = 0.94 ms, Throughput = 1058.57 QPS\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/mnt/llm/feiyue/miniconda3/envs/onnx/lib/python3.11/site-packages/onnxruntime/transformers/bert_perf_test.py\", line 634, in <module>\n",
      "    main()\n",
      "  File \"/mnt/llm/feiyue/miniconda3/envs/onnx/lib/python3.11/site-packages/onnxruntime/transformers/bert_perf_test.py\", line 591, in main\n",
      "    run_performance(model_setting, test_setting, perf_results)\n",
      "  File \"/mnt/llm/feiyue/miniconda3/envs/onnx/lib/python3.11/site-packages/onnxruntime/transformers/bert_perf_test.py\", line 381, in run_performance\n",
      "    run_perf_tests(model_setting, test_setting, perf_results, all_inputs)\n",
      "  File \"/mnt/llm/feiyue/miniconda3/envs/onnx/lib/python3.11/site-packages/onnxruntime/transformers/bert_perf_test.py\", line 352, in run_perf_tests\n",
      "    launch_test(model_setting, test_setting, perf_results, all_inputs, intra_op_num_threads)\n",
      "  File \"/mnt/llm/feiyue/miniconda3/envs/onnx/lib/python3.11/site-packages/onnxruntime/transformers/bert_perf_test.py\", line 328, in launch_test\n",
      "    process.join()\n",
      "  File \"/mnt/llm/feiyue/miniconda3/envs/onnx/lib/python3.11/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/llm/feiyue/miniconda3/envs/onnx/lib/python3.11/multiprocessing/popen_fork.py\", line 43, in wait\n",
      "    return self.poll(os.WNOHANG if timeout == 0.0 else 0)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/llm/feiyue/miniconda3/envs/onnx/lib/python3.11/multiprocessing/popen_fork.py\", line 27, in poll\n",
      "    pid, sts = os.waitpid(self.pid, flag)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python -m onnxruntime.transformers.bert_perf_test --model ./tmp/bge_onnx/model_fp16.onnx --batch_size 1 --sequence_length 512 --opt_level 99 --use_gpu --use_io_binding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test setting TestSetting(batch_size=1, sequence_length=512, test_cases=10, test_times=100, use_gpu=True, use_io_binding=True, provider=None, intra_op_num_threads=None, seed=3, verbose=False, log_severity=2, average_sequence_length=512, random_sequence_length=False)\n",
      "Generating 10 samples for batch_size=1 sequence_length=512\n",
      "./tmp/bge_onnx/model.onnx\n",
      "False\n",
      "<onnxruntime.capi.onnxruntime_pybind11_state.SessionOptions object at 0x7f0e48991ef0>\n",
      "[<onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7f0e48991ef0>, <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7f0e47bc33b0>, <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7f0e486f8930>]\n",
      "[<onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7f0e48991ef0>]\n",
      "\u001b[0;93m2024-07-11 14:24:25.161926851 [W:onnxruntime:, transformer_memcpy.cc:74 ApplyImpl] 4 Memcpy nodes are added to the graph main_graph for CUDAExecutionProvider. It might have negative impact on performance (including unable to run CUDA graph). Set session_options.log_severity_level=1 to see the detail logs before this message.\u001b[m\n",
      "Running test: model=model.onnx,graph_optimization_level=ENABLE_ALL,intra_op_num_threads=32,batch_size=1,sequence_length=512,test_cases=10,test_times=100,use_gpu=True,use_io_binding=True,average_sequence_length=512,random_sequence_length=False\n",
      "Average latency = 1.49 ms, Throughput = 669.01 QPS\n",
      "./tmp/bge_onnx/model.onnx\n",
      "False\n",
      "<onnxruntime.capi.onnxruntime_pybind11_state.SessionOptions object at 0x7f0e47dc3f70>\n",
      "[<onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7f0e47dc3f70>, <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7f0e482d7e30>, <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7f0e47bc3330>]\n",
      "[<onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7f0e47dc3f70>]\n",
      "\u001b[0;93m2024-07-11 14:24:30.817086465 [W:onnxruntime:, transformer_memcpy.cc:74 ApplyImpl] 4 Memcpy nodes are added to the graph main_graph for CUDAExecutionProvider. It might have negative impact on performance (including unable to run CUDA graph). Set session_options.log_severity_level=1 to see the detail logs before this message.\u001b[m\n",
      "Running test: model=model.onnx,graph_optimization_level=ENABLE_ALL,intra_op_num_threads=16,batch_size=1,sequence_length=512,test_cases=10,test_times=100,use_gpu=True,use_io_binding=True,average_sequence_length=512,random_sequence_length=False\n",
      "Average latency = 1.50 ms, Throughput = 668.70 QPS\n",
      "./tmp/bge_onnx/model.onnx\n",
      "False\n",
      "<onnxruntime.capi.onnxruntime_pybind11_state.SessionOptions object at 0x7f0e483f9270>\n",
      "[<onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7f0e483f9270>, <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7f0e47dc3d70>, <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7f0e47dc3f70>]\n",
      "[<onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7f0e483f9270>]\n",
      "\u001b[0;93m2024-07-11 14:24:36.443992047 [W:onnxruntime:, transformer_memcpy.cc:74 ApplyImpl] 4 Memcpy nodes are added to the graph main_graph for CUDAExecutionProvider. It might have negative impact on performance (including unable to run CUDA graph). Set session_options.log_severity_level=1 to see the detail logs before this message.\u001b[m\n",
      "Running test: model=model.onnx,graph_optimization_level=ENABLE_ALL,intra_op_num_threads=15,batch_size=1,sequence_length=512,test_cases=10,test_times=100,use_gpu=True,use_io_binding=True,average_sequence_length=512,random_sequence_length=False\n",
      "Average latency = 1.49 ms, Throughput = 669.67 QPS\n",
      "./tmp/bge_onnx/model.onnx\n",
      "False\n",
      "<onnxruntime.capi.onnxruntime_pybind11_state.SessionOptions object at 0x7f0e483f9270>\n",
      "[<onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7f0e483f9270>, <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7f0e47dc3d70>, <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7f0e47dc3f70>]\n",
      "[<onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7f0e483f9270>]\n",
      "\u001b[0;93m2024-07-11 14:24:42.079711145 [W:onnxruntime:, transformer_memcpy.cc:74 ApplyImpl] 4 Memcpy nodes are added to the graph main_graph for CUDAExecutionProvider. It might have negative impact on performance (including unable to run CUDA graph). Set session_options.log_severity_level=1 to see the detail logs before this message.\u001b[m\n",
      "Running test: model=model.onnx,graph_optimization_level=ENABLE_ALL,intra_op_num_threads=14,batch_size=1,sequence_length=512,test_cases=10,test_times=100,use_gpu=True,use_io_binding=True,average_sequence_length=512,random_sequence_length=False\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/mnt/llm/feiyue/miniconda3/envs/onnx/lib/python3.11/site-packages/onnxruntime/transformers/bert_perf_test.py\", line 634, in <module>\n",
      "    main()\n",
      "  File \"/mnt/llm/feiyue/miniconda3/envs/onnx/lib/python3.11/site-packages/onnxruntime/transformers/bert_perf_test.py\", line 591, in main\n",
      "    run_performance(model_setting, test_setting, perf_results)\n",
      "  File \"/mnt/llm/feiyue/miniconda3/envs/onnx/lib/python3.11/site-packages/onnxruntime/transformers/bert_perf_test.py\", line 381, in run_performance\n",
      "    run_perf_tests(model_setting, test_setting, perf_results, all_inputs)\n",
      "  File \"/mnt/llm/feiyue/miniconda3/envs/onnx/lib/python3.11/site-packages/onnxruntime/transformers/bert_perf_test.py\", line 352, in run_perf_tests\n",
      "    launch_test(model_setting, test_setting, perf_results, all_inputs, intra_op_num_threads)\n",
      "Process Process-5:\n",
      "  File \"/mnt/llm/feiyue/miniconda3/envs/onnx/lib/python3.11/site-packages/onnxruntime/transformers/bert_perf_test.py\", line 328, in launch_test\n",
      "    process.join()\n",
      "  File \"/mnt/llm/feiyue/miniconda3/envs/onnx/lib/python3.11/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/llm/feiyue/miniconda3/envs/onnx/lib/python3.11/multiprocessing/popen_fork.py\", line 43, in wait\n",
      "Traceback (most recent call last):\n",
      "    return self.poll(os.WNOHANG if timeout == 0.0 else 0)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/llm/feiyue/miniconda3/envs/onnx/lib/python3.11/multiprocessing/popen_fork.py\", line 27, in poll\n",
      "  File \"/mnt/llm/feiyue/miniconda3/envs/onnx/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/mnt/llm/feiyue/miniconda3/envs/onnx/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/mnt/llm/feiyue/miniconda3/envs/onnx/lib/python3.11/site-packages/onnxruntime/transformers/bert_perf_test.py\", line 269, in run_one_test\n",
      "    results, latency_list = onnxruntime_inference_with_io_binding(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/llm/feiyue/miniconda3/envs/onnx/lib/python3.11/site-packages/onnxruntime/transformers/bert_perf_test.py\", line 196, in onnxruntime_inference_with_io_binding\n",
      "    result = session.run(output_names, inputs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/llm/feiyue/miniconda3/envs/onnx/lib/python3.11/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py\", line 220, in run\n",
      "    return self._sess.run(output_names, input_feed, run_options)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "    pid, sts = os.waitpid(self.pid, flag)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python -m onnxruntime.transformers.bert_perf_test --model ./tmp/bge_onnx/model.onnx --batch_size 1 --sequence_length 512 --use_gpu --use_io_binding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test setting TestSetting(batch_size=1, sequence_length=512, test_cases=10, test_times=100, use_gpu=True, use_io_binding=True, provider=None, intra_op_num_threads=None, seed=3, verbose=False, log_severity=2, average_sequence_length=512, random_sequence_length=False)\n",
      "Generating 10 samples for batch_size=1 sequence_length=512\n",
      "./tmp/bge_onnx/model_fp16.onnx\n",
      "False\n",
      "<onnxruntime.capi.onnxruntime_pybind11_state.SessionOptions object at 0x7fc834b9bf70>\n",
      "[<onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7fc834b9bf70>, <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7fc833cf1170>, <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7fc833cf11b0>]\n",
      "[<onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7fc835c8be30>]\n",
      "\u001b[0;93m2024-07-11 16:32:34.436910944 [W:onnxruntime:, transformer_memcpy.cc:74 ApplyImpl] 8 Memcpy nodes are added to the graph main_graph for CUDAExecutionProvider. It might have negative impact on performance (including unable to run CUDA graph). Set session_options.log_severity_level=1 to see the detail logs before this message.\u001b[m\n",
      "Running test: model=model_fp16.onnx,graph_optimization_level=ENABLE_ALL,intra_op_num_threads=32,batch_size=1,sequence_length=512,test_cases=10,test_times=100,use_gpu=True,use_io_binding=True,average_sequence_length=512,random_sequence_length=False\n",
      "Average latency = 0.94 ms, Throughput = 1068.57 QPS\n",
      "./tmp/bge_onnx/model_fp16.onnx\n",
      "False\n",
      "<onnxruntime.capi.onnxruntime_pybind11_state.SessionOptions object at 0x7fc834b9bf70>\n",
      "[<onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7fc834b9bf70>, <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7fc833cf1170>, <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7fc833cf11b0>]\n",
      "[<onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7fc835c8be30>]\n",
      "\u001b[0;93m2024-07-11 16:32:38.258498065 [W:onnxruntime:, transformer_memcpy.cc:74 ApplyImpl] 8 Memcpy nodes are added to the graph main_graph for CUDAExecutionProvider. It might have negative impact on performance (including unable to run CUDA graph). Set session_options.log_severity_level=1 to see the detail logs before this message.\u001b[m\n",
      "Running test: model=model_fp16.onnx,graph_optimization_level=ENABLE_ALL,intra_op_num_threads=16,batch_size=1,sequence_length=512,test_cases=10,test_times=100,use_gpu=True,use_io_binding=True,average_sequence_length=512,random_sequence_length=False\n",
      "Average latency = 0.94 ms, Throughput = 1068.48 QPS\n",
      "./tmp/bge_onnx/model_fp16.onnx\n",
      "False\n",
      "<onnxruntime.capi.onnxruntime_pybind11_state.SessionOptions object at 0x7fc834b9bf70>\n",
      "[<onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7fc834b9bf70>, <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7fc833cf10b0>, <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7fc833cf11f0>]\n",
      "[<onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7fc835c8be30>]\n",
      "\u001b[0;93m2024-07-11 16:32:42.120317567 [W:onnxruntime:, transformer_memcpy.cc:74 ApplyImpl] 8 Memcpy nodes are added to the graph main_graph for CUDAExecutionProvider. It might have negative impact on performance (including unable to run CUDA graph). Set session_options.log_severity_level=1 to see the detail logs before this message.\u001b[m\n",
      "Running test: model=model_fp16.onnx,graph_optimization_level=ENABLE_ALL,intra_op_num_threads=15,batch_size=1,sequence_length=512,test_cases=10,test_times=100,use_gpu=True,use_io_binding=True,average_sequence_length=512,random_sequence_length=False\n",
      "Average latency = 0.94 ms, Throughput = 1066.13 QPS\n",
      "./tmp/bge_onnx/model_fp16.onnx\n",
      "False\n",
      "<onnxruntime.capi.onnxruntime_pybind11_state.SessionOptions object at 0x7fc834b9bf70>\n",
      "[<onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7fc834b9bf70>, <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7fc833cf10f0>, <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7fc833cf1270>]\n",
      "[<onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7fc835c8be30>]\n",
      "\u001b[0;93m2024-07-11 16:32:45.999854290 [W:onnxruntime:, transformer_memcpy.cc:74 ApplyImpl] 8 Memcpy nodes are added to the graph main_graph for CUDAExecutionProvider. It might have negative impact on performance (including unable to run CUDA graph). Set session_options.log_severity_level=1 to see the detail logs before this message.\u001b[m\n",
      "Running test: model=model_fp16.onnx,graph_optimization_level=ENABLE_ALL,intra_op_num_threads=14,batch_size=1,sequence_length=512,test_cases=10,test_times=100,use_gpu=True,use_io_binding=True,average_sequence_length=512,random_sequence_length=False\n",
      "Average latency = 0.94 ms, Throughput = 1060.35 QPS\n",
      "./tmp/bge_onnx/model_fp16.onnx\n",
      "False\n",
      "<onnxruntime.capi.onnxruntime_pybind11_state.SessionOptions object at 0x7fc834b9bf70>\n",
      "[<onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7fc834b9bf70>, <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7fc833cf1170>, <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7fc833cf12b0>]\n",
      "[<onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7fc835c8be30>]\n",
      "\u001b[0;93m2024-07-11 16:32:49.891700797 [W:onnxruntime:, transformer_memcpy.cc:74 ApplyImpl] 8 Memcpy nodes are added to the graph main_graph for CUDAExecutionProvider. It might have negative impact on performance (including unable to run CUDA graph). Set session_options.log_severity_level=1 to see the detail logs before this message.\u001b[m\n",
      "Running test: model=model_fp16.onnx,graph_optimization_level=ENABLE_ALL,intra_op_num_threads=13,batch_size=1,sequence_length=512,test_cases=10,test_times=100,use_gpu=True,use_io_binding=True,average_sequence_length=512,random_sequence_length=False\n",
      "Average latency = 0.95 ms, Throughput = 1052.50 QPS\n",
      "./tmp/bge_onnx/model_fp16.onnx\n",
      "False\n",
      "<onnxruntime.capi.onnxruntime_pybind11_state.SessionOptions object at 0x7fc834b9bf70>\n",
      "[<onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7fc834b9bf70>, <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7fc833cf1370>, <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7fc833cf1230>]\n",
      "[<onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7fc835c8be30>]\n",
      "\u001b[0;93m2024-07-11 16:32:53.790396613 [W:onnxruntime:, transformer_memcpy.cc:74 ApplyImpl] 8 Memcpy nodes are added to the graph main_graph for CUDAExecutionProvider. It might have negative impact on performance (including unable to run CUDA graph). Set session_options.log_severity_level=1 to see the detail logs before this message.\u001b[m\n",
      "Running test: model=model_fp16.onnx,graph_optimization_level=ENABLE_ALL,intra_op_num_threads=12,batch_size=1,sequence_length=512,test_cases=10,test_times=100,use_gpu=True,use_io_binding=True,average_sequence_length=512,random_sequence_length=False\n",
      "Average latency = 0.95 ms, Throughput = 1054.33 QPS\n",
      "./tmp/bge_onnx/model_fp16.onnx\n",
      "False\n",
      "<onnxruntime.capi.onnxruntime_pybind11_state.SessionOptions object at 0x7fc834b9bf70>\n",
      "[<onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7fc834b9bf70>, <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7fc833cf1270>, <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7fc833cf13b0>]\n",
      "[<onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7fc835c8be30>]\n",
      "\u001b[0;93m2024-07-11 16:32:57.681555150 [W:onnxruntime:, transformer_memcpy.cc:74 ApplyImpl] 8 Memcpy nodes are added to the graph main_graph for CUDAExecutionProvider. It might have negative impact on performance (including unable to run CUDA graph). Set session_options.log_severity_level=1 to see the detail logs before this message.\u001b[m\n",
      "Running test: model=model_fp16.onnx,graph_optimization_level=ENABLE_ALL,intra_op_num_threads=11,batch_size=1,sequence_length=512,test_cases=10,test_times=100,use_gpu=True,use_io_binding=True,average_sequence_length=512,random_sequence_length=False\n",
      "Average latency = 0.95 ms, Throughput = 1052.58 QPS\n",
      "./tmp/bge_onnx/model_fp16.onnx\n",
      "False\n",
      "<onnxruntime.capi.onnxruntime_pybind11_state.SessionOptions object at 0x7fc834b9bf70>\n",
      "[<onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7fc834b9bf70>, <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7fc833cf1470>, <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7fc833cf1370>]\n",
      "[<onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7fc835c8be30>]\n",
      "\u001b[0;93m2024-07-11 16:33:01.570681471 [W:onnxruntime:, transformer_memcpy.cc:74 ApplyImpl] 8 Memcpy nodes are added to the graph main_graph for CUDAExecutionProvider. It might have negative impact on performance (including unable to run CUDA graph). Set session_options.log_severity_level=1 to see the detail logs before this message.\u001b[m\n",
      "Running test: model=model_fp16.onnx,graph_optimization_level=ENABLE_ALL,intra_op_num_threads=10,batch_size=1,sequence_length=512,test_cases=10,test_times=100,use_gpu=True,use_io_binding=True,average_sequence_length=512,random_sequence_length=False\n",
      "Average latency = 0.95 ms, Throughput = 1050.45 QPS\n",
      "./tmp/bge_onnx/model_fp16.onnx\n",
      "False\n",
      "<onnxruntime.capi.onnxruntime_pybind11_state.SessionOptions object at 0x7fc834b9bf70>\n",
      "[<onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7fc834b9bf70>, <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7fc833cf1530>, <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7fc833cf13b0>]\n",
      "[<onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7fc835c8be30>]\n",
      "\u001b[0;93m2024-07-11 16:33:05.507162765 [W:onnxruntime:, transformer_memcpy.cc:74 ApplyImpl] 8 Memcpy nodes are added to the graph main_graph for CUDAExecutionProvider. It might have negative impact on performance (including unable to run CUDA graph). Set session_options.log_severity_level=1 to see the detail logs before this message.\u001b[m\n",
      "Running test: model=model_fp16.onnx,graph_optimization_level=ENABLE_ALL,intra_op_num_threads=9,batch_size=1,sequence_length=512,test_cases=10,test_times=100,use_gpu=True,use_io_binding=True,average_sequence_length=512,random_sequence_length=False\n",
      "Average latency = 0.95 ms, Throughput = 1055.61 QPS\n",
      "./tmp/bge_onnx/model_fp16.onnx\n",
      "False\n",
      "<onnxruntime.capi.onnxruntime_pybind11_state.SessionOptions object at 0x7fc834b9bf70>\n",
      "[<onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7fc834b9bf70>, <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7fc833cf15f0>, <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7fc833cf1470>]\n",
      "[<onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7fc835c8be30>]\n",
      "\u001b[0;93m2024-07-11 16:33:09.436283171 [W:onnxruntime:, transformer_memcpy.cc:74 ApplyImpl] 8 Memcpy nodes are added to the graph main_graph for CUDAExecutionProvider. It might have negative impact on performance (including unable to run CUDA graph). Set session_options.log_severity_level=1 to see the detail logs before this message.\u001b[m\n",
      "Running test: model=model_fp16.onnx,graph_optimization_level=ENABLE_ALL,intra_op_num_threads=8,batch_size=1,sequence_length=512,test_cases=10,test_times=100,use_gpu=True,use_io_binding=True,average_sequence_length=512,random_sequence_length=False\n",
      "Average latency = 0.95 ms, Throughput = 1049.15 QPS\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/mnt/llm/feiyue/miniconda3/envs/onnx/lib/python3.11/site-packages/onnxruntime/transformers/bert_perf_test.py\", line 634, in <module>\n",
      "    main()\n",
      "  File \"/mnt/llm/feiyue/miniconda3/envs/onnx/lib/python3.11/site-packages/onnxruntime/transformers/bert_perf_test.py\", line 591, in main\n",
      "    run_performance(model_setting, test_setting, perf_results)\n",
      "  File \"/mnt/llm/feiyue/miniconda3/envs/onnx/lib/python3.11/site-packages/onnxruntime/transformers/bert_perf_test.py\", line 381, in run_performance\n",
      "    run_perf_tests(model_setting, test_setting, perf_results, all_inputs)\n",
      "  File \"/mnt/llm/feiyue/miniconda3/envs/onnx/lib/python3.11/site-packages/onnxruntime/transformers/bert_perf_test.py\", line 352, in run_perf_tests\n",
      "    launch_test(model_setting, test_setting, perf_results, all_inputs, intra_op_num_threads)\n",
      "  File \"/mnt/llm/feiyue/miniconda3/envs/onnx/lib/python3.11/site-packages/onnxruntime/transformers/bert_perf_test.py\", line 328, in launch_test\n",
      "    process.join()\n",
      "  File \"/mnt/llm/feiyue/miniconda3/envs/onnx/lib/python3.11/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/llm/feiyue/miniconda3/envs/onnx/lib/python3.11/multiprocessing/popen_fork.py\", line 43, in wait\n",
      "    return self.poll(os.WNOHANG if timeout == 0.0 else 0)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/llm/feiyue/miniconda3/envs/onnx/lib/python3.11/multiprocessing/popen_fork.py\", line 27, in poll\n",
      "    pid, sts = os.waitpid(self.pid, flag)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "\u001b[0;93m2024-07-11 16:33:13.366633176 [W:onnxruntime:, transformer_memcpy.cc:74 ApplyImpl] 8 Memcpy nodes are added to the graph main_graph for CUDAExecutionProvider. It might have negative impact on performance (including unable to run CUDA graph). Set session_options.log_severity_level=1 to see the detail logs before this message.\u001b[m\n",
      "Process Process-12:\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/llm/feiyue/miniconda3/envs/onnx/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/mnt/llm/feiyue/miniconda3/envs/onnx/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/mnt/llm/feiyue/miniconda3/envs/onnx/lib/python3.11/site-packages/onnxruntime/transformers/bert_perf_test.py\", line 248, in run_one_test\n",
      "    session = create_session(\n",
      "              ^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/llm/feiyue/miniconda3/envs/onnx/lib/python3.11/site-packages/onnxruntime/transformers/bert_perf_test.py\", line 125, in create_session\n",
      "    session = onnxruntime.InferenceSession(model_path, sess_options, providers=execution_providers)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/llm/feiyue/miniconda3/envs/onnx/lib/python3.11/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py\", line 419, in __init__\n",
      "    self._create_inference_session(providers, provider_options, disabled_optimizers)\n",
      "  File \"/mnt/llm/feiyue/miniconda3/envs/onnx/lib/python3.11/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py\", line 489, in _create_inference_session\n",
      "    sess.initialize_session(providers, provider_options, disabled_optimizers)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python -m onnxruntime.transformers.bert_perf_test --model ./tmp/bge_onnx/model_fp16.onnx --batch_size 1 --sequence_length 512 --use_gpu --use_io_binding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arguments Namespace(input=None, model='./tmp/bge_onnx/model.onnx', batch_size=1, sequence_length=128, past_sequence_length=1, global_length=1, samples=1000, threshold=0.01, thread_num=-1, input_ids_name=None, segment_ids_name=None, input_mask_name=None, dummy_inputs='bert', use_gpu=True, provider='cuda', basic_optimization=False, kernel_time_only=False, verbose=False)\n",
      "./tmp/bge_onnx/model.onnx\n",
      "False\n",
      "<onnxruntime.capi.onnxruntime_pybind11_state.SessionOptions object at 0x7f997b9c8570>\n",
      "[<onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7f997b9c8570>, <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7f997b9c85b0>, <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7f997b9c85f0>]\n",
      "[<onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7f997b9c8570>]\n",
      "loading profile output onnxruntime_profile__2024-07-11_14-12-19.json ...\n",
      "No kernel record found!\n",
      "\n",
      "Nodes in the original order:\n",
      "----------------------------------------------------------------\n",
      "Total(μs)\tTime%\tAcc %\tAvg(μs)\tCalls\tProvider\tNode\n",
      "     14037\t 0.56\t 0.56\t     4.7\t 3000\tCUDA    \t/Shape\n",
      "      9964\t 0.40\t 0.95\t     3.3\t 3000\tCPU     \t/Gather\n",
      "      9283\t 0.37\t 1.32\t     3.1\t 3000\tCPU     \t/embeddings/Unsqueeze\n",
      "     19950\t 0.79\t 2.11\t     6.7\t 3000\tCUDA    \t/embeddings/Slice\n",
      "     13819\t 0.55\t 2.66\t     4.6\t 3000\tCUDA    \t/embeddings/position_embeddings/Gather\n",
      "     12189\t 0.48\t 3.14\t     4.1\t 3000\tCUDA    \t/embeddings/token_type_embeddings/Gather\n",
      "     11982\t 0.48\t 3.62\t     4.0\t 3000\tCUDA    \t/embeddings/word_embeddings/Gather\n",
      "     13954\t 0.55\t 4.17\t     4.7\t 3000\tCUDA    \t/embeddings/Add\n",
      "     11802\t 0.47\t 4.64\t     3.9\t 3000\tCUDA    \t/embeddings/Add_1\n",
      "     13952\t 0.55\t 5.19\t     4.7\t 3000\tCUDA    \t/embeddings/LayerNorm/Mul/LayerNormFusion/\n",
      "      8786\t 0.35\t 5.54\t     2.9\t 3000\tCUDA    \t/encoder/layer.0/attention/self/Shape_1\n",
      "     42112\t 1.67\t 7.21\t    14.0\t 3000\tCUDA    \t/encoder/layer.0/attention/self/query/MatMul\n",
      "     13033\t 0.52\t 7.73\t     4.3\t 3000\tCUDA    \t/encoder/layer.0/attention/self/query/Add\n",
      "      9491\t 0.38\t 8.11\t     3.2\t 3000\tCUDA    \t/encoder/layer.0/attention/self/Reshape\n",
      "      8497\t 0.34\t 8.44\t     2.8\t 3000\tCUDA    \t/encoder/layer.0/attention/self/Shape_8\n",
      "      9213\t 0.37\t 8.81\t     3.1\t 3000\tCPU     \t/encoder/layer.0/attention/self/Gather_1\n",
      "      8677\t 0.34\t 9.15\t     2.9\t 3000\tCPU     \t/encoder/layer.0/attention/self/Unsqueeze_7\n",
      "      8766\t 0.35\t 9.50\t     2.9\t 3000\tCPU     \t/encoder/layer.0/attention/self/Gather\n",
      "      8321\t 0.33\t 9.83\t     2.8\t 3000\tCPU     \t/encoder/layer.0/attention/self/Unsqueeze_6\n",
      "     10475\t 0.42\t10.25\t     3.5\t 3000\tCPU     \t/encoder/layer.0/attention/self/Concat_3\n",
      "      9247\t 0.37\t10.61\t     3.1\t 3000\tCPU     \tGather\n",
      "     10530\t 0.42\t11.03\t     3.5\t 3000\tCPU     \t/encoder/layer.0/attention/self/Slice\n",
      "      8454\t 0.34\t11.37\t     2.8\t 3000\tCPU     \t/encoder/layer.0/attention/self/Cast\n",
      "      8571\t 0.34\t11.71\t     2.9\t 3000\tCPU     \t/encoder/layer.0/attention/self/Sqrt\n",
      "      9523\t 0.38\t12.08\t     3.2\t 3000\tCPU     \t/encoder/layer.0/attention/self/Div\n",
      "      8147\t 0.32\t12.41\t     2.7\t 3000\tCPU     \t/encoder/layer.0/attention/self/Sqrt_2\n",
      "     11394\t 0.45\t12.86\t     3.8\t 3000\tCUDA    \tMemcpy\n",
      "     19204\t 0.76\t13.62\t     6.4\t 3000\tCUDA    \t/encoder/layer.0/attention/self/key/MatMul\n",
      "     12438\t 0.49\t14.11\t     4.1\t 3000\tCUDA    \t/encoder/layer.0/attention/self/key/Add\n",
      "      9284\t 0.37\t14.48\t     3.1\t 3000\tCUDA    \t/encoder/layer.0/attention/self/Reshape_1\n",
      "     13884\t 0.55\t15.03\t     4.6\t 3000\tCUDA    \t/encoder/layer.0/attention/self/Transpose_2\n",
      "     74117\t 2.94\t17.97\t    24.7\t 3000\tCUDA    \t/encoder/layer.0/attention/self/Mul_1\n",
      "     12837\t 0.51\t18.48\t     4.3\t 3000\tCUDA    \t/encoder/layer.0/attention/self/Transpose\n",
      "     11497\t 0.46\t18.94\t     3.8\t 3000\tCUDA    \t/encoder/layer.0/attention/self/Mul\n",
      "     16508\t 0.65\t19.59\t     5.5\t 3000\tCUDA    \t/encoder/layer.0/attention/self/MatMul\n",
      "      9398\t 0.37\t19.97\t     3.1\t 3000\tCUDA    \t/Unsqueeze\n",
      "      9213\t 0.37\t20.33\t     3.1\t 3000\tCUDA    \t/Unsqueeze_1\n",
      "      8950\t 0.36\t20.69\t     3.0\t 3000\tCPU     \t/Gather_1\n",
      "      8351\t 0.33\t21.02\t     2.8\t 3000\tCPU     \t/Unsqueeze_2\n",
      "      9890\t 0.39\t21.41\t     3.3\t 3000\tCPU     \t/Concat\n",
      "      8908\t 0.35\t21.76\t     3.0\t 3000\tCPU     \t/Reshape\n",
      "      9543\t 0.38\t22.14\t     3.2\t 3000\tCPU     \t/Equal\n",
      "     11593\t 0.46\t22.60\t     3.9\t 3000\tCPU     \t/Where\n",
      "     14435\t 0.57\t23.17\t     4.8\t 3000\tCUDA    \t/Expand\n",
      "     19225\t 0.76\t23.94\t     6.4\t 3000\tCUDA    \t/Cast\n",
      "     12633\t 0.50\t24.44\t     4.2\t 3000\tCUDA    \t/Sub\n",
      "     12011\t 0.48\t24.91\t     4.0\t 3000\tCUDA    \t/Cast_1\n",
      "     20147\t 0.80\t25.71\t     6.7\t 3000\tCUDA    \t/Where_1\n",
      "     12376\t 0.49\t26.20\t     4.1\t 3000\tCUDA    \t/encoder/layer.0/attention/self/Add\n",
      "     15037\t 0.60\t26.80\t     5.0\t 3000\tCUDA    \t/encoder/layer.0/attention/self/Softmax\n",
      "     18796\t 0.75\t27.55\t     6.3\t 3000\tCUDA    \t/encoder/layer.0/attention/self/value/MatMul\n",
      "     12239\t 0.49\t28.03\t     4.1\t 3000\tCUDA    \t/encoder/layer.0/attention/self/value/Add\n",
      "      9193\t 0.36\t28.40\t     3.1\t 3000\tCUDA    \t/encoder/layer.0/attention/self/Reshape_2\n",
      "     12079\t 0.48\t28.87\t     4.0\t 3000\tCUDA    \t/encoder/layer.0/attention/self/Transpose_1\n",
      "     15325\t 0.61\t29.48\t     5.1\t 3000\tCUDA    \t/encoder/layer.0/attention/self/MatMul_1\n",
      "     11773\t 0.47\t29.95\t     3.9\t 3000\tCUDA    \t/encoder/layer.0/attention/self/Transpose_3\n",
      "      9237\t 0.37\t30.32\t     3.1\t 3000\tCUDA    \t/encoder/layer.0/attention/self/Reshape_3\n",
      "     17484\t 0.69\t31.01\t     5.8\t 3000\tCUDA    \t/encoder/layer.0/attention/output/dense/MatMul\n",
      "     11980\t 0.48\t31.48\t     4.0\t 3000\tCUDA    \t/encoder/layer.0/attention/output/dense/Add\n",
      "     11612\t 0.46\t31.95\t     3.9\t 3000\tCUDA    \t/encoder/layer.0/attention/output/Add\n",
      "     12964\t 0.51\t32.46\t     4.3\t 3000\tCUDA    \t/encoder/layer.0/attention/output/LayerNorm/Mul/LayerNormFusion/\n",
      "     17494\t 0.69\t33.15\t     5.8\t 3000\tCUDA    \t/encoder/layer.0/intermediate/dense/MatMul\n",
      "     12666\t 0.50\t33.66\t     4.2\t 3000\tCUDA    \tBiasGelu\n",
      "     17849\t 0.71\t34.36\t     5.9\t 3000\tCUDA    \t/encoder/layer.0/output/dense/MatMul\n",
      "     12136\t 0.48\t34.85\t     4.0\t 3000\tCUDA    \t/encoder/layer.0/output/dense/Add\n",
      "     11487\t 0.46\t35.30\t     3.8\t 3000\tCUDA    \t/encoder/layer.0/output/Add\n",
      "     12342\t 0.49\t35.79\t     4.1\t 3000\tCUDA    \t/encoder/layer.0/output/LayerNorm/Mul/LayerNormFusion/\n",
      "      8364\t 0.33\t36.12\t     2.8\t 3000\tCUDA    \t/encoder/layer.1/attention/self/Shape_1\n",
      "     17469\t 0.69\t36.82\t     5.8\t 3000\tCUDA    \t/encoder/layer.1/attention/self/query/MatMul\n",
      "     12253\t 0.49\t37.30\t     4.1\t 3000\tCUDA    \t/encoder/layer.1/attention/self/query/Add\n",
      "      9195\t 0.36\t37.67\t     3.1\t 3000\tCUDA    \t/encoder/layer.1/attention/self/Reshape\n",
      "      8232\t 0.33\t37.99\t     2.7\t 3000\tCUDA    \t/encoder/layer.1/attention/self/Shape_8\n",
      "      9173\t 0.36\t38.36\t     3.1\t 3000\tCPU     \t/encoder/layer.1/attention/self/Gather_1\n",
      "      8496\t 0.34\t38.69\t     2.8\t 3000\tCPU     \t/encoder/layer.1/attention/self/Unsqueeze_7\n",
      "      8463\t 0.34\t39.03\t     2.8\t 3000\tCPU     \t/encoder/layer.1/attention/self/Gather\n",
      "      8406\t 0.33\t39.36\t     2.8\t 3000\tCPU     \t/encoder/layer.1/attention/self/Unsqueeze_6\n",
      "      9609\t 0.38\t39.74\t     3.2\t 3000\tCPU     \t/encoder/layer.1/attention/self/Concat_3\n",
      "     10012\t 0.40\t40.14\t     3.3\t 3000\tCPU     \tGather_token_1\n",
      "     11606\t 0.46\t40.60\t     3.9\t 3000\tCPU     \t/encoder/layer.1/attention/self/Slice\n",
      "      8894\t 0.35\t40.95\t     3.0\t 3000\tCPU     \t/encoder/layer.1/attention/self/Cast\n",
      "      8891\t 0.35\t41.31\t     3.0\t 3000\tCPU     \t/encoder/layer.1/attention/self/Sqrt\n",
      "      9785\t 0.39\t41.69\t     3.3\t 3000\tCPU     \t/encoder/layer.1/attention/self/Div\n",
      "      8744\t 0.35\t42.04\t     2.9\t 3000\tCPU     \t/encoder/layer.1/attention/self/Sqrt_2\n",
      "     12597\t 0.50\t42.54\t     4.2\t 3000\tCUDA    \tMemcpy_token_12\n",
      "     19638\t 0.78\t43.32\t     6.5\t 3000\tCUDA    \t/encoder/layer.1/attention/self/key/MatMul\n",
      "     13097\t 0.52\t43.84\t     4.4\t 3000\tCUDA    \t/encoder/layer.1/attention/self/key/Add\n",
      "      9850\t 0.39\t44.23\t     3.3\t 3000\tCUDA    \t/encoder/layer.1/attention/self/Reshape_1\n",
      "     13170\t 0.52\t44.75\t     4.4\t 3000\tCUDA    \t/encoder/layer.1/attention/self/Transpose_2\n",
      "     12602\t 0.50\t45.25\t     4.2\t 3000\tCUDA    \t/encoder/layer.1/attention/self/Mul_1\n",
      "     12334\t 0.49\t45.74\t     4.1\t 3000\tCUDA    \t/encoder/layer.1/attention/self/Transpose\n",
      "     11957\t 0.47\t46.22\t     4.0\t 3000\tCUDA    \t/encoder/layer.1/attention/self/Mul\n",
      "     15801\t 0.63\t46.84\t     5.3\t 3000\tCUDA    \t/encoder/layer.1/attention/self/MatMul\n",
      "     12815\t 0.51\t47.35\t     4.3\t 3000\tCUDA    \t/encoder/layer.1/attention/self/Add\n",
      "     12303\t 0.49\t47.84\t     4.1\t 3000\tCUDA    \t/encoder/layer.1/attention/self/Softmax\n",
      "     18426\t 0.73\t48.57\t     6.1\t 3000\tCUDA    \t/encoder/layer.1/attention/self/value/MatMul\n",
      "     12587\t 0.50\t49.07\t     4.2\t 3000\tCUDA    \t/encoder/layer.1/attention/self/value/Add\n",
      "      9803\t 0.39\t49.46\t     3.3\t 3000\tCUDA    \t/encoder/layer.1/attention/self/Reshape_2\n",
      "     12294\t 0.49\t49.95\t     4.1\t 3000\tCUDA    \t/encoder/layer.1/attention/self/Transpose_1\n",
      "     15215\t 0.60\t50.55\t     5.1\t 3000\tCUDA    \t/encoder/layer.1/attention/self/MatMul_1\n",
      "     12208\t 0.48\t51.03\t     4.1\t 3000\tCUDA    \t/encoder/layer.1/attention/self/Transpose_3\n",
      "      9779\t 0.39\t51.42\t     3.3\t 3000\tCUDA    \t/encoder/layer.1/attention/self/Reshape_3\n",
      "     18219\t 0.72\t52.14\t     6.1\t 3000\tCUDA    \t/encoder/layer.1/attention/output/dense/MatMul\n",
      "     12555\t 0.50\t52.64\t     4.2\t 3000\tCUDA    \t/encoder/layer.1/attention/output/dense/Add\n",
      "     12034\t 0.48\t53.12\t     4.0\t 3000\tCUDA    \t/encoder/layer.1/attention/output/Add\n",
      "     13369\t 0.53\t53.65\t     4.5\t 3000\tCUDA    \t/encoder/layer.1/attention/output/LayerNorm/Mul/LayerNormFusion/\n",
      "     18300\t 0.73\t54.38\t     6.1\t 3000\tCUDA    \t/encoder/layer.1/intermediate/dense/MatMul\n",
      "     12381\t 0.49\t54.87\t     4.1\t 3000\tCUDA    \tBiasGelu_token_9\n",
      "     18227\t 0.72\t55.59\t     6.1\t 3000\tCUDA    \t/encoder/layer.1/output/dense/MatMul\n",
      "     12764\t 0.51\t56.10\t     4.3\t 3000\tCUDA    \t/encoder/layer.1/output/dense/Add\n",
      "     12087\t 0.48\t56.58\t     4.0\t 3000\tCUDA    \t/encoder/layer.1/output/Add\n",
      "     12965\t 0.51\t57.09\t     4.3\t 3000\tCUDA    \t/encoder/layer.1/output/LayerNorm/Mul/LayerNormFusion/\n",
      "      8886\t 0.35\t57.44\t     3.0\t 3000\tCUDA    \t/encoder/layer.2/attention/self/Shape_1\n",
      "     18198\t 0.72\t58.16\t     6.1\t 3000\tCUDA    \t/encoder/layer.2/attention/self/query/MatMul\n",
      "     12680\t 0.50\t58.67\t     4.2\t 3000\tCUDA    \t/encoder/layer.2/attention/self/query/Add\n",
      "      9754\t 0.39\t59.05\t     3.3\t 3000\tCUDA    \t/encoder/layer.2/attention/self/Reshape\n",
      "     10241\t 0.41\t59.46\t     3.4\t 3000\tCUDA    \t/encoder/layer.2/attention/self/Shape_8\n",
      "      9785\t 0.39\t59.85\t     3.3\t 3000\tCPU     \t/encoder/layer.2/attention/self/Gather_1\n",
      "      9115\t 0.36\t60.21\t     3.0\t 3000\tCPU     \t/encoder/layer.2/attention/self/Unsqueeze_7\n",
      "      8858\t 0.35\t60.56\t     3.0\t 3000\tCPU     \t/encoder/layer.2/attention/self/Gather\n",
      "      8847\t 0.35\t60.91\t     2.9\t 3000\tCPU     \t/encoder/layer.2/attention/self/Unsqueeze_6\n",
      "     10074\t 0.40\t61.31\t     3.4\t 3000\tCPU     \t/encoder/layer.2/attention/self/Concat_3\n",
      "      9728\t 0.39\t61.70\t     3.2\t 3000\tCPU     \tGather_token_3\n",
      "     10429\t 0.41\t62.11\t     3.5\t 3000\tCPU     \t/encoder/layer.2/attention/self/Slice\n",
      "      8717\t 0.35\t62.46\t     2.9\t 3000\tCPU     \t/encoder/layer.2/attention/self/Cast\n",
      "      8794\t 0.35\t62.81\t     2.9\t 3000\tCPU     \t/encoder/layer.2/attention/self/Sqrt\n",
      "      9698\t 0.38\t63.19\t     3.2\t 3000\tCPU     \t/encoder/layer.2/attention/self/Div\n",
      "      8732\t 0.35\t63.54\t     2.9\t 3000\tCPU     \t/encoder/layer.2/attention/self/Sqrt_2\n",
      "     12011\t 0.48\t64.01\t     4.0\t 3000\tCUDA    \tMemcpy_token_13\n",
      "     19375\t 0.77\t64.78\t     6.5\t 3000\tCUDA    \t/encoder/layer.2/attention/self/key/MatMul\n",
      "     13171\t 0.52\t65.30\t     4.4\t 3000\tCUDA    \t/encoder/layer.2/attention/self/key/Add\n",
      "      9747\t 0.39\t65.69\t     3.2\t 3000\tCUDA    \t/encoder/layer.2/attention/self/Reshape_1\n",
      "     12981\t 0.51\t66.21\t     4.3\t 3000\tCUDA    \t/encoder/layer.2/attention/self/Transpose_2\n",
      "     12540\t 0.50\t66.70\t     4.2\t 3000\tCUDA    \t/encoder/layer.2/attention/self/Mul_1\n",
      "     12350\t 0.49\t67.19\t     4.1\t 3000\tCUDA    \t/encoder/layer.2/attention/self/Transpose\n",
      "     11932\t 0.47\t67.67\t     4.0\t 3000\tCUDA    \t/encoder/layer.2/attention/self/Mul\n",
      "     15804\t 0.63\t68.29\t     5.3\t 3000\tCUDA    \t/encoder/layer.2/attention/self/MatMul\n",
      "     12756\t 0.51\t68.80\t     4.3\t 3000\tCUDA    \t/encoder/layer.2/attention/self/Add\n",
      "     12137\t 0.48\t69.28\t     4.0\t 3000\tCUDA    \t/encoder/layer.2/attention/self/Softmax\n",
      "     18196\t 0.72\t70.00\t     6.1\t 3000\tCUDA    \t/encoder/layer.2/attention/self/value/MatMul\n",
      "     12436\t 0.49\t70.50\t     4.1\t 3000\tCUDA    \t/encoder/layer.2/attention/self/value/Add\n",
      "      9792\t 0.39\t70.88\t     3.3\t 3000\tCUDA    \t/encoder/layer.2/attention/self/Reshape_2\n",
      "     12202\t 0.48\t71.37\t     4.1\t 3000\tCUDA    \t/encoder/layer.2/attention/self/Transpose_1\n",
      "     15224\t 0.60\t71.97\t     5.1\t 3000\tCUDA    \t/encoder/layer.2/attention/self/MatMul_1\n",
      "     12133\t 0.48\t72.45\t     4.0\t 3000\tCUDA    \t/encoder/layer.2/attention/self/Transpose_3\n",
      "      9657\t 0.38\t72.84\t     3.2\t 3000\tCUDA    \t/encoder/layer.2/attention/self/Reshape_3\n",
      "     18134\t 0.72\t73.56\t     6.0\t 3000\tCUDA    \t/encoder/layer.2/attention/output/dense/MatMul\n",
      "     12440\t 0.49\t74.05\t     4.1\t 3000\tCUDA    \t/encoder/layer.2/attention/output/dense/Add\n",
      "     11915\t 0.47\t74.52\t     4.0\t 3000\tCUDA    \t/encoder/layer.2/attention/output/Add\n",
      "     12896\t 0.51\t75.03\t     4.3\t 3000\tCUDA    \t/encoder/layer.2/attention/output/LayerNorm/Mul/LayerNormFusion/\n",
      "     18168\t 0.72\t75.75\t     6.1\t 3000\tCUDA    \t/encoder/layer.2/intermediate/dense/MatMul\n",
      "     12516\t 0.50\t76.25\t     4.2\t 3000\tCUDA    \tBiasGelu_token_10\n",
      "     18219\t 0.72\t76.97\t     6.1\t 3000\tCUDA    \t/encoder/layer.2/output/dense/MatMul\n",
      "     12733\t 0.51\t77.48\t     4.2\t 3000\tCUDA    \t/encoder/layer.2/output/dense/Add\n",
      "     12485\t 0.50\t77.97\t     4.2\t 3000\tCUDA    \t/encoder/layer.2/output/Add\n",
      "     13659\t 0.54\t78.51\t     4.6\t 3000\tCUDA    \t/encoder/layer.2/output/LayerNorm/Mul/LayerNormFusion/\n",
      "      8936\t 0.35\t78.87\t     3.0\t 3000\tCUDA    \t/encoder/layer.3/attention/self/Shape_1\n",
      "     18289\t 0.73\t79.59\t     6.1\t 3000\tCUDA    \t/encoder/layer.3/attention/self/query/MatMul\n",
      "     12767\t 0.51\t80.10\t     4.3\t 3000\tCUDA    \t/encoder/layer.3/attention/self/query/Add\n",
      "      9808\t 0.39\t80.49\t     3.3\t 3000\tCUDA    \t/encoder/layer.3/attention/self/Reshape\n",
      "      8849\t 0.35\t80.84\t     2.9\t 3000\tCUDA    \t/encoder/layer.3/attention/self/Shape_8\n",
      "      9643\t 0.38\t81.22\t     3.2\t 3000\tCPU     \t/encoder/layer.3/attention/self/Gather_1\n",
      "      9000\t 0.36\t81.58\t     3.0\t 3000\tCPU     \t/encoder/layer.3/attention/self/Unsqueeze_7\n",
      "      8912\t 0.35\t81.93\t     3.0\t 3000\tCPU     \t/encoder/layer.3/attention/self/Gather\n",
      "      8897\t 0.35\t82.29\t     3.0\t 3000\tCPU     \t/encoder/layer.3/attention/self/Unsqueeze_6\n",
      "     10160\t 0.40\t82.69\t     3.4\t 3000\tCPU     \t/encoder/layer.3/attention/self/Concat_3\n",
      "      9727\t 0.39\t83.08\t     3.2\t 3000\tCPU     \tGather_token_5\n",
      "     10406\t 0.41\t83.49\t     3.5\t 3000\tCPU     \t/encoder/layer.3/attention/self/Slice\n",
      "      8807\t 0.35\t83.84\t     2.9\t 3000\tCPU     \t/encoder/layer.3/attention/self/Cast\n",
      "      8752\t 0.35\t84.18\t     2.9\t 3000\tCPU     \t/encoder/layer.3/attention/self/Sqrt\n",
      "      9706\t 0.38\t84.57\t     3.2\t 3000\tCPU     \t/encoder/layer.3/attention/self/Div\n",
      "      8694\t 0.34\t84.91\t     2.9\t 3000\tCPU     \t/encoder/layer.3/attention/self/Sqrt_2\n",
      "     11908\t 0.47\t85.39\t     4.0\t 3000\tCUDA    \tMemcpy_token_14\n",
      "     19383\t 0.77\t86.16\t     6.5\t 3000\tCUDA    \t/encoder/layer.3/attention/self/key/MatMul\n",
      "     12968\t 0.51\t86.67\t     4.3\t 3000\tCUDA    \t/encoder/layer.3/attention/self/key/Add\n",
      "      9692\t 0.38\t87.05\t     3.2\t 3000\tCUDA    \t/encoder/layer.3/attention/self/Reshape_1\n",
      "     12990\t 0.52\t87.57\t     4.3\t 3000\tCUDA    \t/encoder/layer.3/attention/self/Transpose_2\n",
      "     12577\t 0.50\t88.07\t     4.2\t 3000\tCUDA    \t/encoder/layer.3/attention/self/Mul_1\n",
      "     12352\t 0.49\t88.56\t     4.1\t 3000\tCUDA    \t/encoder/layer.3/attention/self/Transpose\n",
      "     11844\t 0.47\t89.03\t     3.9\t 3000\tCUDA    \t/encoder/layer.3/attention/self/Mul\n",
      "     15775\t 0.63\t89.65\t     5.3\t 3000\tCUDA    \t/encoder/layer.3/attention/self/MatMul\n",
      "     12644\t 0.50\t90.16\t     4.2\t 3000\tCUDA    \t/encoder/layer.3/attention/self/Add\n",
      "     12165\t 0.48\t90.64\t     4.1\t 3000\tCUDA    \t/encoder/layer.3/attention/self/Softmax\n",
      "     18199\t 0.72\t91.36\t     6.1\t 3000\tCUDA    \t/encoder/layer.3/attention/self/value/MatMul\n",
      "     12500\t 0.50\t91.86\t     4.2\t 3000\tCUDA    \t/encoder/layer.3/attention/self/value/Add\n",
      "      9745\t 0.39\t92.24\t     3.2\t 3000\tCUDA    \t/encoder/layer.3/attention/self/Reshape_2\n",
      "     12334\t 0.49\t92.73\t     4.1\t 3000\tCUDA    \t/encoder/layer.3/attention/self/Transpose_1\n",
      "     15140\t 0.60\t93.33\t     5.0\t 3000\tCUDA    \t/encoder/layer.3/attention/self/MatMul_1\n",
      "     12091\t 0.48\t93.81\t     4.0\t 3000\tCUDA    \t/encoder/layer.3/attention/self/Transpose_3\n",
      "      9578\t 0.38\t94.19\t     3.2\t 3000\tCUDA    \t/encoder/layer.3/attention/self/Reshape_3\n",
      "     18188\t 0.72\t94.91\t     6.1\t 3000\tCUDA    \t/encoder/layer.3/attention/output/dense/MatMul\n",
      "     12682\t 0.50\t95.42\t     4.2\t 3000\tCUDA    \t/encoder/layer.3/attention/output/dense/Add\n",
      "     11983\t 0.48\t95.89\t     4.0\t 3000\tCUDA    \t/encoder/layer.3/attention/output/Add\n",
      "     13824\t 0.55\t96.44\t     4.6\t 3000\tCUDA    \t/encoder/layer.3/attention/output/LayerNorm/Mul/LayerNormFusion/\n",
      "     18440\t 0.73\t97.17\t     6.1\t 3000\tCUDA    \t/encoder/layer.3/intermediate/dense/MatMul\n",
      "     12581\t 0.50\t97.67\t     4.2\t 3000\tCUDA    \tBiasGelu_token_11\n",
      "     18313\t 0.73\t98.40\t     6.1\t 3000\tCUDA    \t/encoder/layer.3/output/dense/MatMul\n",
      "     12675\t 0.50\t98.90\t     4.2\t 3000\tCUDA    \t/encoder/layer.3/output/dense/Add\n",
      "     12030\t 0.48\t99.38\t     4.0\t 3000\tCUDA    \t/encoder/layer.3/output/Add\n",
      "     15708\t 0.62\t100.00\t     5.2\t 3000\tCUDA    \t/encoder/layer.3/output/LayerNorm/Mul/LayerNormFusion/\n",
      "\n",
      "Top expensive nodes with Time% >= 1.00:\n",
      "----------------------------------------------------------------\n",
      "Total(μs)\tTime%\tAvg(μs)\tCalls\tProvider\tNode\n",
      "     74117\t 2.94\t    24.7\t 3000\tCUDA    \t/encoder/layer.0/attention/self/Mul_1\n",
      "     42112\t 1.67\t    14.0\t 3000\tCUDA    \t/encoder/layer.0/attention/self/query/MatMul\n",
      "\n",
      "Grouped by operator\n",
      "----------------------------------------------------------------\n",
      "Total(μs)\tTime%\tKernel(μs)\tKernel%\tCalls\tAvgKernel(μs)\tFence(μs)\tOperator\n",
      "    589112\t23.37\t     589091\t23.37\t32000\t          18.4\t        21\tMatMul\n",
      "    424114\t16.82\t     424050\t16.82\t34000\t          12.5\t        64\tAdd\n",
      "    200012\t 7.93\t     199974\t 7.93\t16000\t          12.5\t        38\tTranspose\n",
      "    168431\t 6.68\t     168402\t 6.68\t17000\t           9.9\t        29\tGather\n",
      "    162513\t 6.45\t     162486\t 6.45\t17000\t           9.6\t        27\tReshape\n",
      "    159066\t 6.31\t     159060\t 6.31\t 8000\t          19.9\t         6\tMul\n",
      "    121679\t 4.83\t     121668\t 4.83\t 9000\t          13.5\t        11\tLayerNormalization\n",
      "    106004\t 4.20\t     105956\t 4.20\t12000\t           8.8\t        48\tUnsqueeze\n",
      "     84828\t 3.36\t      84812\t 3.36\t 9000\t           9.4\t        16\tShape\n",
      "     69325\t 2.75\t      69317\t 2.75\t 8000\t           8.7\t         8\tSqrt\n",
      "     66108\t 2.62\t      66104\t 2.62\t 6000\t          11.0\t         4\tCast\n",
      "     62921\t 2.50\t      62916\t 2.50\t 5000\t          12.6\t         5\tSlice\n",
      "     51642\t 2.05\t      51637\t 2.05\t 4000\t          12.9\t         5\tSoftmax\n",
      "     50208\t 1.99\t      50199\t 1.99\t 5000\t          10.0\t         9\tConcat\n",
      "     50144\t 1.99\t      50144\t 1.99\t 4000\t          12.5\t         0\tBiasGelu\n",
      "     47910\t 1.90\t      47906\t 1.90\t 4000\t          12.0\t         4\tMemcpyFromHost\n",
      "     38712\t 1.54\t      38712\t 1.54\t 4000\t           9.7\t         0\tDiv\n",
      "     31740\t 1.26\t      31734\t 1.26\t 2000\t          15.9\t         6\tWhere\n",
      "     14435\t 0.57\t      14435\t 0.57\t 1000\t          14.4\t         0\tExpand\n",
      "     12633\t 0.50\t      12633\t 0.50\t 1000\t          12.6\t         0\tSub\n",
      "      9543\t 0.38\t       9537\t 0.38\t 1000\t           9.5\t         6\tEqual\n",
      "\n",
      "Grouped by provider + operator\n",
      "----------------------------------------------------------------\n",
      "Kernel(μs)\tProvider%\tCalls\tAvgKernel(μs)\tProvider\tOperator\n",
      "    589091\t    28.92\t32000\t          18.4\tCUDA    \tMatMul\n",
      "    424050\t    20.82\t34000\t          12.5\tCUDA    \tAdd\n",
      "    199974\t     9.82\t16000\t          12.5\tCUDA    \tTranspose\n",
      "    159060\t     7.81\t 8000\t          19.9\tCUDA    \tMul\n",
      "    153578\t     7.54\t16000\t           9.6\tCUDA    \tReshape\n",
      "    130424\t    26.95\t14000\t           9.3\tCPU     \tGather\n",
      "    121668\t     5.97\t 9000\t          13.5\tCUDA    \tLayerNormalization\n",
      "     87357\t    18.05\t10000\t           8.7\tCPU     \tUnsqueeze\n",
      "     84812\t     4.16\t 9000\t           9.4\tCUDA    \tShape\n",
      "     69317\t    14.33\t 8000\t           8.7\tCPU     \tSqrt\n",
      "     51637\t     2.54\t 4000\t          12.9\tCUDA    \tSoftmax\n",
      "     50199\t    10.37\t 5000\t          10.0\tCPU     \tConcat\n",
      "     50144\t     2.46\t 4000\t          12.5\tCUDA    \tBiasGelu\n",
      "     47906\t     2.35\t 4000\t          12.0\tCUDA    \tMemcpyFromHost\n",
      "     42966\t     8.88\t 4000\t          10.7\tCPU     \tSlice\n",
      "     38712\t     8.00\t 4000\t           9.7\tCPU     \tDiv\n",
      "     37978\t     1.86\t 3000\t          12.7\tCUDA    \tGather\n",
      "     34868\t     7.21\t 4000\t           8.7\tCPU     \tCast\n",
      "     31236\t     1.53\t 2000\t          15.6\tCUDA    \tCast\n",
      "     20141\t     0.99\t 1000\t          20.1\tCUDA    \tWhere\n",
      "     19950\t     0.98\t 1000\t          19.9\tCUDA    \tSlice\n",
      "     18599\t     0.91\t 2000\t           9.3\tCUDA    \tUnsqueeze\n",
      "     14435\t     0.71\t 1000\t          14.4\tCUDA    \tExpand\n",
      "     12633\t     0.62\t 1000\t          12.6\tCUDA    \tSub\n",
      "     11593\t     2.40\t 1000\t          11.6\tCPU     \tWhere\n",
      "      9537\t     1.97\t 1000\t           9.5\tCPU     \tEqual\n",
      "      8908\t     1.84\t 1000\t           8.9\tCPU     \tReshape\n"
     ]
    }
   ],
   "source": [
    "!python -m onnxruntime.transformers.profiler --model ./tmp/bge_onnx/model.onnx --batch_size 1 --sequence_length 128 --samples 1000 --dummy_inputs bert --use_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arguments Namespace(input=None, model='./tmp/bge_onnx/model_fp16.onnx', batch_size=1, sequence_length=128, past_sequence_length=1, global_length=1, samples=1000, threshold=0.01, thread_num=-1, input_ids_name=None, segment_ids_name=None, input_mask_name=None, dummy_inputs='bert', use_gpu=True, provider='cuda', basic_optimization=False, kernel_time_only=False, verbose=False)\n",
      "./tmp/bge_onnx/model_fp16.onnx\n",
      "False\n",
      "<onnxruntime.capi.onnxruntime_pybind11_state.SessionOptions object at 0x7f5f2afbd2f0>\n",
      "[<onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7f5f2afbd2f0>, <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7f5f2afbd330>, <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7f5f2afbd370>]\n",
      "[<onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7f5f2afbd2f0>]\n",
      "loading profile output onnxruntime_profile__2024-07-11_16-31-41.json ...\n",
      "No kernel record found!\n",
      "\n",
      "Nodes in the original order:\n",
      "----------------------------------------------------------------\n",
      "Total(μs)\tTime%\tAcc %\tAvg(μs)\tCalls\tProvider\tNode\n",
      "     21055\t 0.79\t 0.79\t     7.0\t 3000\tCUDA    \t/embeddings/word_embeddings/Gather\n",
      "     12300\t 0.46\t 1.26\t     4.1\t 3000\tCUDA    \t/embeddings/token_type_embeddings/Gather\n",
      "     14316\t 0.54\t 1.80\t     4.8\t 3000\tCUDA    \t/embeddings/Add\n",
      "      9084\t 0.34\t 2.14\t     3.0\t 3000\tCUDA    \t/Shape\n",
      "      9188\t 0.35\t 2.49\t     3.1\t 3000\tCPU     \t/Gather\n",
      "      9482\t 0.36\t 2.84\t     3.2\t 3000\tCPU     \t/embeddings/Unsqueeze\n",
      "     16277\t 0.61\t 3.46\t     5.4\t 3000\tCUDA    \t/embeddings/Slice\n",
      "     12022\t 0.45\t 3.91\t     4.0\t 3000\tCUDA    \t/embeddings/position_embeddings/Gather\n",
      "     11608\t 0.44\t 4.35\t     3.9\t 3000\tCUDA    \t/embeddings/Add_1\n",
      "     13657\t 0.51\t 4.86\t     4.6\t 3000\tCUDA    \t/embeddings/LayerNorm/Mul/LayerNormFusion/\n",
      "     63507\t 2.39\t 7.26\t    21.2\t 3000\tCUDA    \t/encoder/layer.0/attention/self/value/MatMul\n",
      "     12574\t 0.47\t 7.73\t     4.2\t 3000\tCUDA    \t/encoder/layer.0/attention/self/value/Add\n",
      "      9297\t 0.35\t 8.08\t     3.1\t 3000\tCUDA    \t/encoder/layer.0/attention/self/Reshape_2\n",
      "     13547\t 0.51\t 8.59\t     4.5\t 3000\tCUDA    \t/encoder/layer.0/attention/self/Transpose_1\n",
      "      9330\t 0.35\t 8.95\t     3.1\t 3000\tCUDA    \t/Unsqueeze\n",
      "      9173\t 0.35\t 9.29\t     3.1\t 3000\tCUDA    \t/Unsqueeze_1\n",
      "      9096\t 0.34\t 9.63\t     3.0\t 3000\tCPU     \t/Gather_1\n",
      "      8173\t 0.31\t 9.94\t     2.7\t 3000\tCPU     \t/Unsqueeze_2\n",
      "     10230\t 0.39\t10.33\t     3.4\t 3000\tCPU     \t/Concat\n",
      "      8585\t 0.32\t10.65\t     2.9\t 3000\tCPU     \t/Reshape\n",
      "      9635\t 0.36\t11.02\t     3.2\t 3000\tCPU     \t/Equal\n",
      "     11277\t 0.43\t11.44\t     3.8\t 3000\tCPU     \t/Where\n",
      "     13612\t 0.51\t11.95\t     4.5\t 3000\tCUDA    \t/Expand\n",
      "     18943\t 0.71\t12.67\t     6.3\t 3000\tCUDA    \t/Cast\n",
      "     73469\t 2.77\t15.44\t    24.5\t 3000\tCUDA    \t/Sub\n",
      "     11388\t 0.43\t15.87\t     3.8\t 3000\tCUDA    \t/Cast_1\n",
      "     18612\t 0.70\t16.57\t     6.2\t 3000\tCUDA    \t/Where_1\n",
      "     19947\t 0.75\t17.32\t     6.6\t 3000\tCUDA    \t/encoder/layer.0/attention/self/query/MatMul\n",
      "     12283\t 0.46\t17.79\t     4.1\t 3000\tCUDA    \t/encoder/layer.0/attention/self/query/Add\n",
      "      9165\t 0.35\t18.13\t     3.1\t 3000\tCUDA    \t/encoder/layer.0/attention/self/Reshape\n",
      "     12108\t 0.46\t18.59\t     4.0\t 3000\tCUDA    \t/encoder/layer.0/attention/self/Transpose\n",
      "      8217\t 0.31\t18.90\t     2.7\t 3000\tCUDA    \t/encoder/layer.0/attention/self/Shape_8\n",
      "      8829\t 0.33\t19.23\t     2.9\t 3000\tCPU     \tGather\n",
      "     10529\t 0.40\t19.63\t     3.5\t 3000\tCPU     \t/encoder/layer.0/attention/self/Slice\n",
      "      8585\t 0.32\t19.95\t     2.9\t 3000\tCPU     \t/encoder/layer.0/attention/self/Cast\n",
      "     12217\t 0.46\t20.41\t     4.1\t 3000\tCUDA    \tMemcpy_token_0\n",
      "     11712\t 0.44\t20.85\t     3.9\t 3000\tCUDA    \t/encoder/layer.0/attention/self/Sqrt\n",
      "     12220\t 0.46\t21.31\t     4.1\t 3000\tCUDA    \t/encoder/layer.0/attention/self/Div\n",
      "     10805\t 0.41\t21.72\t     3.6\t 3000\tCUDA    \t/encoder/layer.0/attention/self/Sqrt_2\n",
      "     11703\t 0.44\t22.16\t     3.9\t 3000\tCUDA    \tMemcpy_token_5\n",
      "     10237\t 0.39\t22.55\t     3.4\t 3000\tCUDA    \tMemcpy\n",
      "     12463\t 0.47\t23.02\t     4.2\t 3000\tCUDA    \t/encoder/layer.0/attention/self/Mul\n",
      "     19347\t 0.73\t23.75\t     6.4\t 3000\tCUDA    \t/encoder/layer.0/attention/self/key/MatMul\n",
      "     12221\t 0.46\t24.21\t     4.1\t 3000\tCUDA    \t/encoder/layer.0/attention/self/key/Add\n",
      "      9142\t 0.34\t24.55\t     3.0\t 3000\tCUDA    \t/encoder/layer.0/attention/self/Reshape_1\n",
      "     12573\t 0.47\t25.03\t     4.2\t 3000\tCUDA    \t/encoder/layer.0/attention/self/Transpose_2\n",
      "     11326\t 0.43\t25.45\t     3.8\t 3000\tCUDA    \t/encoder/layer.0/attention/self/Mul_1\n",
      "     20221\t 0.76\t26.22\t     6.7\t 3000\tCUDA    \t/encoder/layer.0/attention/self/MatMul\n",
      "     12325\t 0.46\t26.68\t     4.1\t 3000\tCUDA    \t/encoder/layer.0/attention/self/Add\n",
      "     14577\t 0.55\t27.23\t     4.9\t 3000\tCUDA    \t/encoder/layer.0/attention/self/Softmax\n",
      "     14564\t 0.55\t27.78\t     4.9\t 3000\tCUDA    \t/encoder/layer.0/attention/self/MatMul_1\n",
      "     11988\t 0.45\t28.23\t     4.0\t 3000\tCUDA    \t/encoder/layer.0/attention/self/Transpose_3\n",
      "      8163\t 0.31\t28.54\t     2.7\t 3000\tCUDA    \t/encoder/layer.0/attention/self/Shape_1\n",
      "      8430\t 0.32\t28.86\t     2.8\t 3000\tCPU     \t/encoder/layer.0/attention/self/Gather\n",
      "      8431\t 0.32\t29.18\t     2.8\t 3000\tCPU     \t/encoder/layer.0/attention/self/Unsqueeze_6\n",
      "      8236\t 0.31\t29.49\t     2.7\t 3000\tCPU     \t/encoder/layer.0/attention/self/Gather_1\n",
      "      8118\t 0.31\t29.79\t     2.7\t 3000\tCPU     \t/encoder/layer.0/attention/self/Unsqueeze_7\n",
      "      9727\t 0.37\t30.16\t     3.2\t 3000\tCPU     \t/encoder/layer.0/attention/self/Concat_3\n",
      "      9134\t 0.34\t30.50\t     3.0\t 3000\tCUDA    \t/encoder/layer.0/attention/self/Reshape_3\n",
      "     18552\t 0.70\t31.20\t     6.2\t 3000\tCUDA    \t/encoder/layer.0/attention/output/dense/MatMul\n",
      "     12184\t 0.46\t31.66\t     4.1\t 3000\tCUDA    \t/encoder/layer.0/attention/output/dense/Add\n",
      "     11451\t 0.43\t32.09\t     3.8\t 3000\tCUDA    \t/encoder/layer.0/attention/output/Add\n",
      "     12693\t 0.48\t32.57\t     4.2\t 3000\tCUDA    \t/encoder/layer.0/attention/output/LayerNorm/Mul/LayerNormFusion/\n",
      "     15608\t 0.59\t33.16\t     5.2\t 3000\tCUDA    \t/encoder/layer.0/intermediate/dense/MatMul\n",
      "     12460\t 0.47\t33.63\t     4.2\t 3000\tCUDA    \tBiasGelu\n",
      "     17437\t 0.66\t34.29\t     5.8\t 3000\tCUDA    \t/encoder/layer.0/output/dense/MatMul\n",
      "     12177\t 0.46\t34.75\t     4.1\t 3000\tCUDA    \t/encoder/layer.0/output/dense/Add\n",
      "     11239\t 0.42\t35.17\t     3.7\t 3000\tCUDA    \t/encoder/layer.0/output/Add\n",
      "     11982\t 0.45\t35.62\t     4.0\t 3000\tCUDA    \t/encoder/layer.0/output/LayerNorm/Mul/LayerNormFusion/\n",
      "     17151\t 0.65\t36.27\t     5.7\t 3000\tCUDA    \t/encoder/layer.1/attention/self/value/MatMul\n",
      "     11841\t 0.45\t36.72\t     3.9\t 3000\tCUDA    \t/encoder/layer.1/attention/self/value/Add\n",
      "      9016\t 0.34\t37.06\t     3.0\t 3000\tCUDA    \t/encoder/layer.1/attention/self/Reshape_2\n",
      "     11803\t 0.45\t37.50\t     3.9\t 3000\tCUDA    \t/encoder/layer.1/attention/self/Transpose_1\n",
      "     17058\t 0.64\t38.15\t     5.7\t 3000\tCUDA    \t/encoder/layer.1/attention/self/query/MatMul\n",
      "     11973\t 0.45\t38.60\t     4.0\t 3000\tCUDA    \t/encoder/layer.1/attention/self/query/Add\n",
      "      9053\t 0.34\t38.94\t     3.0\t 3000\tCUDA    \t/encoder/layer.1/attention/self/Reshape\n",
      "     11468\t 0.43\t39.37\t     3.8\t 3000\tCUDA    \t/encoder/layer.1/attention/self/Transpose\n",
      "      8152\t 0.31\t39.68\t     2.7\t 3000\tCUDA    \t/encoder/layer.1/attention/self/Shape_8\n",
      "     10442\t 0.39\t40.07\t     3.5\t 3000\tCPU     \tGather_token_1\n",
      "     11023\t 0.42\t40.49\t     3.7\t 3000\tCPU     \t/encoder/layer.1/attention/self/Slice\n",
      "      8895\t 0.34\t40.82\t     3.0\t 3000\tCPU     \t/encoder/layer.1/attention/self/Cast\n",
      "     12150\t 0.46\t41.28\t     4.0\t 3000\tCUDA    \tMemcpy_token_1\n",
      "     12135\t 0.46\t41.74\t     4.0\t 3000\tCUDA    \t/encoder/layer.1/attention/self/Sqrt\n",
      "     12441\t 0.47\t42.21\t     4.1\t 3000\tCUDA    \t/encoder/layer.1/attention/self/Div\n",
      "     11286\t 0.43\t42.63\t     3.8\t 3000\tCUDA    \t/encoder/layer.1/attention/self/Sqrt_2\n",
      "     11897\t 0.45\t43.08\t     4.0\t 3000\tCUDA    \tMemcpy_token_7\n",
      "     10815\t 0.41\t43.49\t     3.6\t 3000\tCUDA    \tMemcpy_token_12\n",
      "     12896\t 0.49\t43.98\t     4.3\t 3000\tCUDA    \t/encoder/layer.1/attention/self/Mul\n",
      "     19755\t 0.74\t44.72\t     6.6\t 3000\tCUDA    \t/encoder/layer.1/attention/self/key/MatMul\n",
      "     12871\t 0.49\t45.21\t     4.3\t 3000\tCUDA    \t/encoder/layer.1/attention/self/key/Add\n",
      "      9679\t 0.36\t45.57\t     3.2\t 3000\tCUDA    \t/encoder/layer.1/attention/self/Reshape_1\n",
      "     12653\t 0.48\t46.05\t     4.2\t 3000\tCUDA    \t/encoder/layer.1/attention/self/Transpose_2\n",
      "     11993\t 0.45\t46.50\t     4.0\t 3000\tCUDA    \t/encoder/layer.1/attention/self/Mul_1\n",
      "     16285\t 0.61\t47.11\t     5.4\t 3000\tCUDA    \t/encoder/layer.1/attention/self/MatMul\n",
      "     12724\t 0.48\t47.59\t     4.2\t 3000\tCUDA    \t/encoder/layer.1/attention/self/Add\n",
      "     12325\t 0.46\t48.06\t     4.1\t 3000\tCUDA    \t/encoder/layer.1/attention/self/Softmax\n",
      "     15095\t 0.57\t48.63\t     5.0\t 3000\tCUDA    \t/encoder/layer.1/attention/self/MatMul_1\n",
      "     12576\t 0.47\t49.10\t     4.2\t 3000\tCUDA    \t/encoder/layer.1/attention/self/Transpose_3\n",
      "      8850\t 0.33\t49.44\t     3.0\t 3000\tCUDA    \t/encoder/layer.1/attention/self/Shape_1\n",
      "      9110\t 0.34\t49.78\t     3.0\t 3000\tCPU     \t/encoder/layer.1/attention/self/Gather\n",
      "      9128\t 0.34\t50.12\t     3.0\t 3000\tCPU     \t/encoder/layer.1/attention/self/Unsqueeze_6\n",
      "      8802\t 0.33\t50.46\t     2.9\t 3000\tCPU     \t/encoder/layer.1/attention/self/Gather_1\n",
      "      8711\t 0.33\t50.78\t     2.9\t 3000\tCPU     \t/encoder/layer.1/attention/self/Unsqueeze_7\n",
      "     10237\t 0.39\t51.17\t     3.4\t 3000\tCPU     \t/encoder/layer.1/attention/self/Concat_3\n",
      "      9667\t 0.36\t51.53\t     3.2\t 3000\tCUDA    \t/encoder/layer.1/attention/self/Reshape_3\n",
      "     19073\t 0.72\t52.25\t     6.4\t 3000\tCUDA    \t/encoder/layer.1/attention/output/dense/MatMul\n",
      "     12820\t 0.48\t52.74\t     4.3\t 3000\tCUDA    \t/encoder/layer.1/attention/output/dense/Add\n",
      "     11892\t 0.45\t53.19\t     4.0\t 3000\tCUDA    \t/encoder/layer.1/attention/output/Add\n",
      "     12989\t 0.49\t53.68\t     4.3\t 3000\tCUDA    \t/encoder/layer.1/attention/output/LayerNorm/Mul/LayerNormFusion/\n",
      "     15587\t 0.59\t54.26\t     5.2\t 3000\tCUDA    \t/encoder/layer.1/intermediate/dense/MatMul\n",
      "     12608\t 0.48\t54.74\t     4.2\t 3000\tCUDA    \tBiasGelu_token_9\n",
      "     18024\t 0.68\t55.42\t     6.0\t 3000\tCUDA    \t/encoder/layer.1/output/dense/MatMul\n",
      "     12674\t 0.48\t55.90\t     4.2\t 3000\tCUDA    \t/encoder/layer.1/output/dense/Add\n",
      "     11837\t 0.45\t56.34\t     3.9\t 3000\tCUDA    \t/encoder/layer.1/output/Add\n",
      "     12403\t 0.47\t56.81\t     4.1\t 3000\tCUDA    \t/encoder/layer.1/output/LayerNorm/Mul/LayerNormFusion/\n",
      "     19230\t 0.73\t57.54\t     6.4\t 3000\tCUDA    \t/encoder/layer.2/attention/self/value/MatMul\n",
      "     12669\t 0.48\t58.01\t     4.2\t 3000\tCUDA    \t/encoder/layer.2/attention/self/value/Add\n",
      "      9590\t 0.36\t58.37\t     3.2\t 3000\tCUDA    \t/encoder/layer.2/attention/self/Reshape_2\n",
      "     12512\t 0.47\t58.85\t     4.2\t 3000\tCUDA    \t/encoder/layer.2/attention/self/Transpose_1\n",
      "     18163\t 0.68\t59.53\t     6.1\t 3000\tCUDA    \t/encoder/layer.2/attention/self/query/MatMul\n",
      "     12641\t 0.48\t60.01\t     4.2\t 3000\tCUDA    \t/encoder/layer.2/attention/self/query/Add\n",
      "      9348\t 0.35\t60.36\t     3.1\t 3000\tCUDA    \t/encoder/layer.2/attention/self/Reshape\n",
      "     12163\t 0.46\t60.82\t     4.1\t 3000\tCUDA    \t/encoder/layer.2/attention/self/Transpose\n",
      "      8766\t 0.33\t61.15\t     2.9\t 3000\tCUDA    \t/encoder/layer.2/attention/self/Shape_8\n",
      "      9265\t 0.35\t61.50\t     3.1\t 3000\tCPU     \tGather_token_3\n",
      "     10720\t 0.40\t61.90\t     3.6\t 3000\tCPU     \t/encoder/layer.2/attention/self/Slice\n",
      "      8913\t 0.34\t62.24\t     3.0\t 3000\tCPU     \t/encoder/layer.2/attention/self/Cast\n",
      "     12018\t 0.45\t62.69\t     4.0\t 3000\tCUDA    \tMemcpy_token_2\n",
      "     11947\t 0.45\t63.14\t     4.0\t 3000\tCUDA    \t/encoder/layer.2/attention/self/Sqrt\n",
      "     12269\t 0.46\t63.61\t     4.1\t 3000\tCUDA    \t/encoder/layer.2/attention/self/Div\n",
      "     11179\t 0.42\t64.03\t     3.7\t 3000\tCUDA    \t/encoder/layer.2/attention/self/Sqrt_2\n",
      "     11792\t 0.44\t64.47\t     3.9\t 3000\tCUDA    \tMemcpy_token_9\n",
      "     10698\t 0.40\t64.88\t     3.6\t 3000\tCUDA    \tMemcpy_token_13\n",
      "     12795\t 0.48\t65.36\t     4.3\t 3000\tCUDA    \t/encoder/layer.2/attention/self/Mul\n",
      "     19628\t 0.74\t66.10\t     6.5\t 3000\tCUDA    \t/encoder/layer.2/attention/self/key/MatMul\n",
      "     12704\t 0.48\t66.58\t     4.2\t 3000\tCUDA    \t/encoder/layer.2/attention/self/key/Add\n",
      "      9527\t 0.36\t66.94\t     3.2\t 3000\tCUDA    \t/encoder/layer.2/attention/self/Reshape_1\n",
      "     12523\t 0.47\t67.41\t     4.2\t 3000\tCUDA    \t/encoder/layer.2/attention/self/Transpose_2\n",
      "     11908\t 0.45\t67.86\t     4.0\t 3000\tCUDA    \t/encoder/layer.2/attention/self/Mul_1\n",
      "     16326\t 0.62\t68.47\t     5.4\t 3000\tCUDA    \t/encoder/layer.2/attention/self/MatMul\n",
      "     12653\t 0.48\t68.95\t     4.2\t 3000\tCUDA    \t/encoder/layer.2/attention/self/Add\n",
      "     12112\t 0.46\t69.41\t     4.0\t 3000\tCUDA    \t/encoder/layer.2/attention/self/Softmax\n",
      "     14988\t 0.57\t69.97\t     5.0\t 3000\tCUDA    \t/encoder/layer.2/attention/self/MatMul_1\n",
      "     12316\t 0.46\t70.44\t     4.1\t 3000\tCUDA    \t/encoder/layer.2/attention/self/Transpose_3\n",
      "      8750\t 0.33\t70.77\t     2.9\t 3000\tCUDA    \t/encoder/layer.2/attention/self/Shape_1\n",
      "      8998\t 0.34\t71.11\t     3.0\t 3000\tCPU     \t/encoder/layer.2/attention/self/Gather\n",
      "      9052\t 0.34\t71.45\t     3.0\t 3000\tCPU     \t/encoder/layer.2/attention/self/Unsqueeze_6\n",
      "      8725\t 0.33\t71.78\t     2.9\t 3000\tCPU     \t/encoder/layer.2/attention/self/Gather_1\n",
      "      8738\t 0.33\t72.11\t     2.9\t 3000\tCPU     \t/encoder/layer.2/attention/self/Unsqueeze_7\n",
      "     10121\t 0.38\t72.49\t     3.4\t 3000\tCPU     \t/encoder/layer.2/attention/self/Concat_3\n",
      "      9636\t 0.36\t72.85\t     3.2\t 3000\tCUDA    \t/encoder/layer.2/attention/self/Reshape_3\n",
      "     19122\t 0.72\t73.57\t     6.4\t 3000\tCUDA    \t/encoder/layer.2/attention/output/dense/MatMul\n",
      "     12725\t 0.48\t74.05\t     4.2\t 3000\tCUDA    \t/encoder/layer.2/attention/output/dense/Add\n",
      "     12732\t 0.48\t74.53\t     4.2\t 3000\tCUDA    \t/encoder/layer.2/attention/output/Add\n",
      "     13325\t 0.50\t75.03\t     4.4\t 3000\tCUDA    \t/encoder/layer.2/attention/output/LayerNorm/Mul/LayerNormFusion/\n",
      "     15633\t 0.59\t75.62\t     5.2\t 3000\tCUDA    \t/encoder/layer.2/intermediate/dense/MatMul\n",
      "     12488\t 0.47\t76.09\t     4.2\t 3000\tCUDA    \tBiasGelu_token_10\n",
      "     18064\t 0.68\t76.78\t     6.0\t 3000\tCUDA    \t/encoder/layer.2/output/dense/MatMul\n",
      "     12663\t 0.48\t77.25\t     4.2\t 3000\tCUDA    \t/encoder/layer.2/output/dense/Add\n",
      "     11845\t 0.45\t77.70\t     3.9\t 3000\tCUDA    \t/encoder/layer.2/output/Add\n",
      "     12493\t 0.47\t78.17\t     4.2\t 3000\tCUDA    \t/encoder/layer.2/output/LayerNorm/Mul/LayerNormFusion/\n",
      "     17884\t 0.67\t78.84\t     6.0\t 3000\tCUDA    \t/encoder/layer.3/attention/self/value/MatMul\n",
      "     12522\t 0.47\t79.32\t     4.2\t 3000\tCUDA    \t/encoder/layer.3/attention/self/value/Add\n",
      "      9664\t 0.36\t79.68\t     3.2\t 3000\tCUDA    \t/encoder/layer.3/attention/self/Reshape_2\n",
      "     12490\t 0.47\t80.15\t     4.2\t 3000\tCUDA    \t/encoder/layer.3/attention/self/Transpose_1\n",
      "     17809\t 0.67\t80.82\t     5.9\t 3000\tCUDA    \t/encoder/layer.3/attention/self/query/MatMul\n",
      "     12519\t 0.47\t81.30\t     4.2\t 3000\tCUDA    \t/encoder/layer.3/attention/self/query/Add\n",
      "      9258\t 0.35\t81.65\t     3.1\t 3000\tCUDA    \t/encoder/layer.3/attention/self/Reshape\n",
      "     12048\t 0.45\t82.10\t     4.0\t 3000\tCUDA    \t/encoder/layer.3/attention/self/Transpose\n",
      "      8724\t 0.33\t82.43\t     2.9\t 3000\tCUDA    \t/encoder/layer.3/attention/self/Shape_8\n",
      "      9214\t 0.35\t82.78\t     3.1\t 3000\tCPU     \tGather_token_5\n",
      "     10762\t 0.41\t83.18\t     3.6\t 3000\tCPU     \t/encoder/layer.3/attention/self/Slice\n",
      "      8740\t 0.33\t83.51\t     2.9\t 3000\tCPU     \t/encoder/layer.3/attention/self/Cast\n",
      "     11988\t 0.45\t83.96\t     4.0\t 3000\tCUDA    \tMemcpy_token_3\n",
      "     11950\t 0.45\t84.41\t     4.0\t 3000\tCUDA    \t/encoder/layer.3/attention/self/Sqrt\n",
      "     12263\t 0.46\t84.88\t     4.1\t 3000\tCUDA    \t/encoder/layer.3/attention/self/Div\n",
      "     11130\t 0.42\t85.30\t     3.7\t 3000\tCUDA    \t/encoder/layer.3/attention/self/Sqrt_2\n",
      "     11817\t 0.45\t85.74\t     3.9\t 3000\tCUDA    \tMemcpy_token_11\n",
      "     10849\t 0.41\t86.15\t     3.6\t 3000\tCUDA    \tMemcpy_token_14\n",
      "     12682\t 0.48\t86.63\t     4.2\t 3000\tCUDA    \t/encoder/layer.3/attention/self/Mul\n",
      "     19536\t 0.74\t87.37\t     6.5\t 3000\tCUDA    \t/encoder/layer.3/attention/self/key/MatMul\n",
      "     12733\t 0.48\t87.85\t     4.2\t 3000\tCUDA    \t/encoder/layer.3/attention/self/key/Add\n",
      "      9540\t 0.36\t88.21\t     3.2\t 3000\tCUDA    \t/encoder/layer.3/attention/self/Reshape_1\n",
      "     12402\t 0.47\t88.67\t     4.1\t 3000\tCUDA    \t/encoder/layer.3/attention/self/Transpose_2\n",
      "     11900\t 0.45\t89.12\t     4.0\t 3000\tCUDA    \t/encoder/layer.3/attention/self/Mul_1\n",
      "     16045\t 0.61\t89.73\t     5.3\t 3000\tCUDA    \t/encoder/layer.3/attention/self/MatMul\n",
      "     12702\t 0.48\t90.21\t     4.2\t 3000\tCUDA    \t/encoder/layer.3/attention/self/Add\n",
      "     12038\t 0.45\t90.66\t     4.0\t 3000\tCUDA    \t/encoder/layer.3/attention/self/Softmax\n",
      "     14978\t 0.56\t91.22\t     5.0\t 3000\tCUDA    \t/encoder/layer.3/attention/self/MatMul_1\n",
      "     12299\t 0.46\t91.69\t     4.1\t 3000\tCUDA    \t/encoder/layer.3/attention/self/Transpose_3\n",
      "      8738\t 0.33\t92.02\t     2.9\t 3000\tCUDA    \t/encoder/layer.3/attention/self/Shape_1\n",
      "      9324\t 0.35\t92.37\t     3.1\t 3000\tCPU     \t/encoder/layer.3/attention/self/Gather\n",
      "      9727\t 0.37\t92.74\t     3.2\t 3000\tCPU     \t/encoder/layer.3/attention/self/Unsqueeze_6\n",
      "      8776\t 0.33\t93.07\t     2.9\t 3000\tCPU     \t/encoder/layer.3/attention/self/Gather_1\n",
      "      8750\t 0.33\t93.40\t     2.9\t 3000\tCPU     \t/encoder/layer.3/attention/self/Unsqueeze_7\n",
      "     10148\t 0.38\t93.78\t     3.4\t 3000\tCPU     \t/encoder/layer.3/attention/self/Concat_3\n",
      "      9629\t 0.36\t94.14\t     3.2\t 3000\tCUDA    \t/encoder/layer.3/attention/self/Reshape_3\n",
      "     19120\t 0.72\t94.86\t     6.4\t 3000\tCUDA    \t/encoder/layer.3/attention/output/dense/MatMul\n",
      "     12772\t 0.48\t95.34\t     4.3\t 3000\tCUDA    \t/encoder/layer.3/attention/output/dense/Add\n",
      "     11796\t 0.44\t95.79\t     3.9\t 3000\tCUDA    \t/encoder/layer.3/attention/output/Add\n",
      "     12962\t 0.49\t96.28\t     4.3\t 3000\tCUDA    \t/encoder/layer.3/attention/output/LayerNorm/Mul/LayerNormFusion/\n",
      "     15426\t 0.58\t96.86\t     5.1\t 3000\tCUDA    \t/encoder/layer.3/intermediate/dense/MatMul\n",
      "     12599\t 0.48\t97.34\t     4.2\t 3000\tCUDA    \tBiasGelu_token_11\n",
      "     18023\t 0.68\t98.01\t     6.0\t 3000\tCUDA    \t/encoder/layer.3/output/dense/MatMul\n",
      "     12654\t 0.48\t98.49\t     4.2\t 3000\tCUDA    \t/encoder/layer.3/output/dense/Add\n",
      "     11786\t 0.44\t98.94\t     3.9\t 3000\tCUDA    \t/encoder/layer.3/output/Add\n",
      "     12625\t 0.48\t99.41\t     4.2\t 3000\tCUDA    \t/encoder/layer.3/output/LayerNorm/Mul/LayerNormFusion/\n",
      "     15584\t 0.59\t100.00\t     5.2\t 3000\tCUDA    \tgraph_output_cast0\n",
      "\n",
      "Top expensive nodes with Time% >= 1.00:\n",
      "----------------------------------------------------------------\n",
      "Total(μs)\tTime%\tAvg(μs)\tCalls\tProvider\tNode\n",
      "     73469\t 2.77\t    24.5\t 3000\tCUDA    \t/Sub\n",
      "     63507\t 2.39\t    21.2\t 3000\tCUDA    \t/encoder/layer.0/attention/self/value/MatMul\n",
      "\n",
      "Grouped by operator\n",
      "----------------------------------------------------------------\n",
      "Total(μs)\tTime%\tKernel(μs)\tKernel%\tCalls\tAvgKernel(μs)\tFence(μs)\tOperator\n",
      "    607186\t22.90\t     607152\t22.90\t32000\t          19.0\t        34\tMatMul\n",
      "    421126\t15.88\t     421013\t15.88\t34000\t          12.4\t       113\tAdd\n",
      "    197469\t 7.45\t     197440\t 7.45\t16000\t          12.3\t        29\tTranspose\n",
      "    171812\t 6.48\t     171778\t 6.48\t17000\t          10.1\t        34\tGather\n",
      "    158930\t 5.99\t     158884\t 5.99\t17000\t           9.3\t        46\tReshape\n",
      "    115129\t 4.34\t     115107\t 4.34\t 9000\t          12.8\t        22\tLayerNormalization\n",
      "    106813\t 4.03\t     106790\t 4.03\t12000\t           8.9\t        23\tUnsqueeze\n",
      "     97963\t 3.69\t      97953\t 3.69\t 8000\t          12.2\t        10\tMul\n",
      "     92144\t 3.47\t      92144\t 3.47\t 8000\t          11.5\t         0\tSqrt\n",
      "     90972\t 3.43\t      90964\t 3.43\t 8000\t          11.4\t         8\tMemcpyFromHost\n",
      "     81048\t 3.06\t      81042\t 3.06\t 7000\t          11.6\t         6\tCast\n",
      "     77444\t 2.92\t      77426\t 2.92\t 9000\t           8.6\t        18\tShape\n",
      "     73469\t 2.77\t      73469\t 2.77\t 1000\t          73.5\t         0\tSub\n",
      "     59311\t 2.24\t      59302\t 2.24\t 5000\t          11.9\t         9\tSlice\n",
      "     51052\t 1.93\t      51052\t 1.93\t 4000\t          12.8\t         0\tSoftmax\n",
      "     50463\t 1.90\t      50448\t 1.90\t 5000\t          10.1\t        15\tConcat\n",
      "     50155\t 1.89\t      50149\t 1.89\t 4000\t          12.5\t         6\tBiasGelu\n",
      "     49193\t 1.85\t      49189\t 1.86\t 4000\t          12.3\t         4\tDiv\n",
      "     47209\t 1.78\t      47204\t 1.78\t 4000\t          11.8\t         5\tMemcpyToHost\n",
      "     29889\t 1.13\t      29880\t 1.13\t 2000\t          14.9\t         9\tWhere\n",
      "     13612\t 0.51\t      13612\t 0.51\t 1000\t          13.6\t         0\tExpand\n",
      "      9635\t 0.36\t       9635\t 0.36\t 1000\t           9.6\t         0\tEqual\n",
      "\n",
      "Grouped by provider + operator\n",
      "----------------------------------------------------------------\n",
      "Kernel(μs)\tProvider%\tCalls\tAvgKernel(μs)\tProvider\tOperator\n",
      "    607152\t    26.64\t32000\t          19.0\tCUDA    \tMatMul\n",
      "    421013\t    18.47\t34000\t          12.4\tCUDA    \tAdd\n",
      "    197440\t     8.66\t16000\t          12.3\tCUDA    \tTranspose\n",
      "    150299\t     6.60\t16000\t           9.4\tCUDA    \tReshape\n",
      "    126413\t    33.91\t14000\t           9.0\tCPU     \tGather\n",
      "    115107\t     5.05\t 9000\t          12.8\tCUDA    \tLayerNormalization\n",
      "     97953\t     4.30\t 8000\t          12.2\tCUDA    \tMul\n",
      "     92144\t     4.04\t 8000\t          11.5\tCUDA    \tSqrt\n",
      "     90964\t     3.99\t 8000\t          11.4\tCUDA    \tMemcpyFromHost\n",
      "     88287\t    23.68\t10000\t           8.8\tCPU     \tUnsqueeze\n",
      "     77426\t     3.40\t 9000\t           8.6\tCUDA    \tShape\n",
      "     73469\t     3.22\t 1000\t          73.5\tCUDA    \tSub\n",
      "     51052\t     2.24\t 4000\t          12.8\tCUDA    \tSoftmax\n",
      "     50448\t    13.53\t 5000\t          10.1\tCPU     \tConcat\n",
      "     50149\t     2.20\t 4000\t          12.5\tCUDA    \tBiasGelu\n",
      "     49189\t     2.16\t 4000\t          12.3\tCUDA    \tDiv\n",
      "     47204\t     2.07\t 4000\t          11.8\tCUDA    \tMemcpyToHost\n",
      "     45915\t     2.01\t 3000\t          15.3\tCUDA    \tCast\n",
      "     45365\t     1.99\t 3000\t          15.1\tCUDA    \tGather\n",
      "     43034\t    11.54\t 4000\t          10.8\tCPU     \tSlice\n",
      "     35127\t     9.42\t 4000\t           8.8\tCPU     \tCast\n",
      "     18603\t     0.82\t 1000\t          18.6\tCUDA    \tWhere\n",
      "     18503\t     0.81\t 2000\t           9.3\tCUDA    \tUnsqueeze\n",
      "     16268\t     0.71\t 1000\t          16.3\tCUDA    \tSlice\n",
      "     13612\t     0.60\t 1000\t          13.6\tCUDA    \tExpand\n",
      "     11277\t     3.02\t 1000\t          11.3\tCPU     \tWhere\n",
      "      9635\t     2.58\t 1000\t           9.6\tCPU     \tEqual\n",
      "      8585\t     2.30\t 1000\t           8.6\tCPU     \tReshape\n"
     ]
    }
   ],
   "source": [
    "!python -m onnxruntime.transformers.profiler --model ./tmp/bge_onnx/model_fp16.onnx --batch_size 1 --sequence_length 512 --samples 1000 --dummy_inputs bert --use_gpu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "onnx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: no matches found: optimum[exporters]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index-embeddings-huggingface-optimum in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (0.1.5)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from llama-index-embeddings-huggingface-optimum) (0.10.51)\n",
      "Requirement already satisfied: llama-index-embeddings-huggingface<0.2.0,>=0.1.3 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from llama-index-embeddings-huggingface-optimum) (0.1.5)\n",
      "Requirement already satisfied: optimum<2.0.0,>=1.16.2 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from optimum[exporters]<2.0.0,>=1.16.2->llama-index-embeddings-huggingface-optimum) (1.21.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface-optimum) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface-optimum) (2.0.31)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface-optimum) (3.9.5)\n",
      "Requirement already satisfied: dataclasses-json in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface-optimum) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface-optimum) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface-optimum) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface-optimum) (2024.5.0)\n",
      "Requirement already satisfied: httpx in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface-optimum) (0.27.0)\n",
      "Requirement already satisfied: llama-cloud<0.0.7,>=0.0.6 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface-optimum) (0.0.6)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface-optimum) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface-optimum) (3.3)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface-optimum) (3.8.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface-optimum) (1.26.4)\n",
      "Requirement already satisfied: openai>=1.1.0 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface-optimum) (1.35.7)\n",
      "Requirement already satisfied: pandas in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface-optimum) (2.2.2)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface-optimum) (10.4.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface-optimum) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface-optimum) (8.4.2)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface-optimum) (0.7.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface-optimum) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface-optimum) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface-optimum) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface-optimum) (1.16.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.0 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface<0.2.0,>=0.1.3->llama-index-embeddings-huggingface-optimum) (0.23.4)\n",
      "Requirement already satisfied: torch<3.0.0,>=2.1.2 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from llama-index-embeddings-huggingface<0.2.0,>=0.1.3->llama-index-embeddings-huggingface-optimum) (2.3.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.37.0 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from llama-index-embeddings-huggingface<0.2.0,>=0.1.3->llama-index-embeddings-huggingface-optimum) (4.42.3)\n",
      "Requirement already satisfied: coloredlogs in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from optimum<2.0.0,>=1.16.2->optimum[exporters]<2.0.0,>=1.16.2->llama-index-embeddings-huggingface-optimum) (15.0.1)\n",
      "Requirement already satisfied: sympy in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from optimum<2.0.0,>=1.16.2->optimum[exporters]<2.0.0,>=1.16.2->llama-index-embeddings-huggingface-optimum) (1.12.1)\n",
      "Requirement already satisfied: packaging in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from optimum<2.0.0,>=1.16.2->optimum[exporters]<2.0.0,>=1.16.2->llama-index-embeddings-huggingface-optimum) (24.1)\n",
      "Requirement already satisfied: datasets in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from optimum<2.0.0,>=1.16.2->optimum[exporters]<2.0.0,>=1.16.2->llama-index-embeddings-huggingface-optimum) (2.20.0)\n",
      "Requirement already satisfied: onnx in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from optimum[exporters]<2.0.0,>=1.16.2->llama-index-embeddings-huggingface-optimum) (1.16.1)\n",
      "Requirement already satisfied: onnxruntime in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from optimum[exporters]<2.0.0,>=1.16.2->llama-index-embeddings-huggingface-optimum) (1.18.1)\n",
      "Requirement already satisfied: timm in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from optimum[exporters]<2.0.0,>=1.16.2->llama-index-embeddings-huggingface-optimum) (1.0.7)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface-optimum) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface-optimum) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface-optimum) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface-optimum) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface-optimum) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface-optimum) (4.0.3)\n",
      "Requirement already satisfied: filelock in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface<0.2.0,>=0.1.3->llama-index-embeddings-huggingface-optimum) (3.15.4)\n",
      "Requirement already satisfied: minijinja>=1.0 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface<0.2.0,>=0.1.3->llama-index-embeddings-huggingface-optimum) (2.0.1)\n",
      "Requirement already satisfied: pydantic>=1.10 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from llama-cloud<0.0.7,>=0.0.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface-optimum) (2.8.0)\n",
      "Requirement already satisfied: anyio in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface-optimum) (4.4.0)\n",
      "Requirement already satisfied: certifi in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface-optimum) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface-optimum) (1.0.5)\n",
      "Requirement already satisfied: idna in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface-optimum) (3.7)\n",
      "Requirement already satisfied: sniffio in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface-optimum) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface-optimum) (0.14.0)\n",
      "Requirement already satisfied: click in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface-optimum) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface-optimum) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface-optimum) (2024.5.15)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface-optimum) (1.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface-optimum) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface-optimum) (2.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface-optimum) (3.0.3)\n",
      "Requirement already satisfied: jinja2 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface<0.2.0,>=0.1.3->llama-index-embeddings-huggingface-optimum) (3.1.4)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from transformers<5.0.0,>=4.37.0->llama-index-embeddings-huggingface<0.2.0,>=0.1.3->llama-index-embeddings-huggingface-optimum) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from transformers<5.0.0,>=4.37.0->llama-index-embeddings-huggingface<0.2.0,>=0.1.3->llama-index-embeddings-huggingface-optimum) (0.19.1)\n",
      "Requirement already satisfied: protobuf in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from transformers[sentencepiece]<4.43.0,>=4.26.0->optimum<2.0.0,>=1.16.2->optimum[exporters]<2.0.0,>=1.16.2->llama-index-embeddings-huggingface-optimum) (5.27.2)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from transformers[sentencepiece]<4.43.0,>=4.26.0->optimum<2.0.0,>=1.16.2->optimum[exporters]<2.0.0,>=1.16.2->llama-index-embeddings-huggingface-optimum) (0.2.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface-optimum) (1.0.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from coloredlogs->optimum<2.0.0,>=1.16.2->optimum[exporters]<2.0.0,>=1.16.2->llama-index-embeddings-huggingface-optimum) (10.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface-optimum) (3.21.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from datasets->optimum<2.0.0,>=1.16.2->optimum[exporters]<2.0.0,>=1.16.2->llama-index-embeddings-huggingface-optimum) (16.1.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from datasets->optimum<2.0.0,>=1.16.2->optimum[exporters]<2.0.0,>=1.16.2->llama-index-embeddings-huggingface-optimum) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from datasets->optimum<2.0.0,>=1.16.2->optimum[exporters]<2.0.0,>=1.16.2->llama-index-embeddings-huggingface-optimum) (0.3.8)\n",
      "Requirement already satisfied: xxhash in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from datasets->optimum<2.0.0,>=1.16.2->optimum[exporters]<2.0.0,>=1.16.2->llama-index-embeddings-huggingface-optimum) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from datasets->optimum<2.0.0,>=1.16.2->optimum[exporters]<2.0.0,>=1.16.2->llama-index-embeddings-huggingface-optimum) (0.70.16)\n",
      "Requirement already satisfied: flatbuffers in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from onnxruntime->optimum[exporters]<2.0.0,>=1.16.2->llama-index-embeddings-huggingface-optimum) (24.3.25)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface-optimum) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface-optimum) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface-optimum) (2024.1)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from sympy->optimum<2.0.0,>=1.16.2->optimum[exporters]<2.0.0,>=1.16.2->llama-index-embeddings-huggingface-optimum) (1.3.0)\n",
      "Requirement already satisfied: torchvision in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from timm->optimum[exporters]<2.0.0,>=1.16.2->llama-index-embeddings-huggingface-optimum) (0.18.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface-optimum) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from pydantic>=1.10->llama-cloud<0.0.7,>=0.0.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface-optimum) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.0 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from pydantic>=1.10->llama-cloud<0.0.7,>=0.0.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface-optimum) (2.20.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface-optimum) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from jinja2->torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface<0.2.0,>=0.1.3->llama-index-embeddings-huggingface-optimum) (2.1.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index-embeddings-huggingface==0.2.0\n",
      "  Using cached llama_index_embeddings_huggingface-0.2.0-py3-none-any.whl.metadata (725 bytes)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.0 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface==0.2.0) (0.23.4)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from llama-index-embeddings-huggingface==0.2.0) (0.10.51)\n",
      "Collecting sentence-transformers<3.0.0,>=2.6.1 (from llama-index-embeddings-huggingface==0.2.0)\n",
      "  Downloading sentence_transformers-2.7.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: filelock in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface==0.2.0) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface==0.2.0) (2024.5.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface==0.2.0) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface==0.2.0) (6.0.1)\n",
      "Requirement already satisfied: requests in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface==0.2.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface==0.2.0) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface==0.2.0) (4.12.2)\n",
      "Requirement already satisfied: aiohttp in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface==0.2.0) (3.9.5)\n",
      "Requirement already satisfied: minijinja>=1.0 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface==0.2.0) (2.0.1)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.2.0) (2.0.31)\n",
      "Requirement already satisfied: dataclasses-json in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.2.0) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.2.0) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.2.0) (1.0.8)\n",
      "Requirement already satisfied: httpx in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.2.0) (0.27.0)\n",
      "Requirement already satisfied: llama-cloud<0.0.7,>=0.0.6 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.2.0) (0.0.6)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.2.0) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.2.0) (3.3)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.2.0) (3.8.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.2.0) (1.26.4)\n",
      "Requirement already satisfied: openai>=1.1.0 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.2.0) (1.35.7)\n",
      "Requirement already satisfied: pandas in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.2.0) (2.2.2)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.2.0) (10.4.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.2.0) (8.4.2)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.2.0) (0.7.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.2.0) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.2.0) (1.16.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface==0.2.0) (4.42.3)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface==0.2.0) (2.3.1)\n",
      "Collecting scikit-learn (from sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface==0.2.0)\n",
      "  Downloading scikit_learn-1.5.0-cp310-cp310-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Collecting scipy (from sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface==0.2.0)\n",
      "  Downloading scipy-1.14.0-cp310-cp310-macosx_14_0_arm64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: aiosignal>=1.1.2 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface==0.2.0) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface==0.2.0) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface==0.2.0) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface==0.2.0) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface==0.2.0) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface==0.2.0) (4.0.3)\n",
      "Requirement already satisfied: pydantic>=1.10 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from llama-cloud<0.0.7,>=0.0.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.2.0) (2.8.0)\n",
      "Requirement already satisfied: anyio in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.2.0) (4.4.0)\n",
      "Requirement already satisfied: certifi in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.2.0) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.2.0) (1.0.5)\n",
      "Requirement already satisfied: idna in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.2.0) (3.7)\n",
      "Requirement already satisfied: sniffio in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.2.0) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.2.0) (0.14.0)\n",
      "Requirement already satisfied: click in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.2.0) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.2.0) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.2.0) (2024.5.15)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.2.0) (1.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface==0.2.0) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface==0.2.0) (2.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.2.0) (3.0.3)\n",
      "Requirement already satisfied: sympy in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface==0.2.0) (1.12.1)\n",
      "Requirement already satisfied: jinja2 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface==0.2.0) (3.1.4)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface==0.2.0) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface==0.2.0) (0.19.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.2.0) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.2.0) (3.21.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.2.0) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.2.0) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.2.0) (2024.1)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface==0.2.0)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.2.0) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from pydantic>=1.10->llama-cloud<0.0.7,>=0.0.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.2.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.0 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from pydantic>=1.10->llama-cloud<0.0.7,>=0.0.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.2.0) (2.20.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface==0.2.0) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface==0.2.0) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/miniconda3/envs/onnx/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface==0.2.0) (1.3.0)\n",
      "Using cached llama_index_embeddings_huggingface-0.2.0-py3-none-any.whl (7.1 kB)\n",
      "Downloading sentence_transformers-2.7.0-py3-none-any.whl (171 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.5/171.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.5.0-cp310-cp310-macosx_12_0_arm64.whl (11.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.14.0-cp310-cp310-macosx_14_0_arm64.whl (23.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.1/23.1 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, scikit-learn, sentence-transformers, llama-index-embeddings-huggingface\n",
      "  Attempting uninstall: llama-index-embeddings-huggingface\n",
      "    Found existing installation: llama-index-embeddings-huggingface 0.1.5\n",
      "    Uninstalling llama-index-embeddings-huggingface-0.1.5:\n",
      "      Successfully uninstalled llama-index-embeddings-huggingface-0.1.5\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "llama-index-embeddings-huggingface-optimum 0.1.5 requires llama-index-embeddings-huggingface<0.2.0,>=0.1.3, but you have llama-index-embeddings-huggingface 0.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed llama-index-embeddings-huggingface-0.2.0 scikit-learn-1.5.0 scipy-1.14.0 sentence-transformers-2.7.0 threadpoolctl-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers optimum[exporters]\n",
    "!pip install llama-index-embeddings-huggingface-optimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/feiyue/huggingface/sentence_transformers/bge-small-zh-v1.5'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "model_dir = \"/Users/feiyue/huggingface/sentence_transformers\"\n",
    "model_name = \"bge-small-zh-v1.5\"\n",
    "\n",
    "model_path = os.path.join(model_dir, model_name)\n",
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/onnx/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Framework not specified. Using pt to export the model.\n",
      "Using the export variant default. Available variants are:\n",
      "    - default: The default ONNX variant.\n",
      "\n",
      "***** Exporting submodel 1/1: BertModel *****\n",
      "Using framework PyTorch: 2.3.1\n",
      "Overriding 1 configuration item(s)\n",
      "\t- use_cache -> False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved optimum model to ./bge_onnx. Use it with `embed_model = OptimumEmbedding(folder_name='./bge_onnx')`.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.embeddings.huggingface_optimum import OptimumEmbedding\n",
    "\n",
    "OptimumEmbedding.create_and_save_optimum_model(model_path, \"./bge_onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.huggingface_optimum import OptimumEmbedding\n",
    "\n",
    "embed_model = OptimumEmbedding(folder_name=\"./bge_onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 49.2 s, sys: 268 ms, total: 49.5 s\n",
      "Wall time: 10 s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "for i in range(5000):\n",
    "    embeddings = embed_model.get_text_embedding(\n",
    "        \"It is raining cats and dogs here!\"\n",
    "    )\n",
    "#embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/feiyue/huggingface/sentence_transformers/bge-small-zh-v1.5'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "BertModel.__init__() got an unexpected keyword argument 'safe_serialization'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:3\u001b[0m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/onnx/lib/python3.10/site-packages/llama_index/embeddings/huggingface/base.py:83\u001b[0m, in \u001b[0;36mHuggingFaceEmbedding.__init__\u001b[0;34m(self, model_name, tokenizer_name, pooling, max_length, query_instruction, text_instruction, normalize, model, tokenizer, embed_batch_size, cache_folder, trust_remote_code, device, callback_manager, safe_serialization)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# Use model_name with AutoModel\u001b[39;00m\n\u001b[1;32m     78\u001b[0m     model_name \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     79\u001b[0m         model_name\n\u001b[1;32m     80\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m model_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     81\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m DEFAULT_HUGGINGFACE_EMBEDDING_MODEL\n\u001b[1;32m     82\u001b[0m     )\n\u001b[0;32m---> 83\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m        \u001b[49m\u001b[43msafe_serialization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe_serialization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m model_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# Extract model_name from model\u001b[39;00m\n\u001b[1;32m     90\u001b[0m     model_name \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mname_or_path\n",
      "File \u001b[0;32m/opt/miniconda3/envs/onnx/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:564\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    563\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    570\u001b[0m )\n",
      "File \u001b[0;32m/opt/miniconda3/envs/onnx/lib/python3.10/site-packages/transformers/modeling_utils.py:3710\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3704\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_autoset_attn_implementation(\n\u001b[1;32m   3705\u001b[0m     config, use_flash_attention_2\u001b[38;5;241m=\u001b[39muse_flash_attention_2, torch_dtype\u001b[38;5;241m=\u001b[39mtorch_dtype, device_map\u001b[38;5;241m=\u001b[39mdevice_map\n\u001b[1;32m   3706\u001b[0m )\n\u001b[1;32m   3708\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ContextManagers(init_contexts):\n\u001b[1;32m   3709\u001b[0m     \u001b[38;5;66;03m# Let's make sure we don't run the init function of buffer modules\u001b[39;00m\n\u001b[0;32m-> 3710\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3712\u001b[0m \u001b[38;5;66;03m# make sure we use the model's config since the __init__ call might have copied it\u001b[39;00m\n\u001b[1;32m   3713\u001b[0m config \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\n",
      "\u001b[0;31mTypeError\u001b[0m: BertModel.__init__() got an unexpected keyword argument 'safe_serialization'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "embed_model2 = HuggingFaceEmbedding(model_name=model_path, safe_serialization=False)\n",
    "for i in range(1000):\n",
    "    embeddings = embed_model2.get_text_embedding(\"It is raining cats and dogs here!\")\n",
    "# embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class HuggingFaceEmbedding in module llama_index.embeddings.huggingface.base:\n",
      "\n",
      "class HuggingFaceEmbedding(llama_index.core.base.embeddings.base.BaseEmbedding)\n",
      " |  HuggingFaceEmbedding(model_name: Optional[str] = None, tokenizer_name: Optional[str] = None, pooling: Union[str, llama_index.embeddings.huggingface.pooling.Pooling] = 'cls', max_length: Optional[int] = None, query_instruction: Optional[str] = None, text_instruction: Optional[str] = None, normalize: bool = True, model: Optional[Any] = None, tokenizer: Optional[Any] = None, embed_batch_size: int = 10, cache_folder: Optional[str] = None, trust_remote_code: bool = False, device: Optional[str] = None, callback_manager: Optional[llama_index.core.callbacks.base.CallbackManager] = None, safe_serialization: Optional[bool] = None) -> None\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      HuggingFaceEmbedding\n",
      " |      llama_index.core.base.embeddings.base.BaseEmbedding\n",
      " |      llama_index.core.schema.TransformComponent\n",
      " |      llama_index.core.schema.BaseComponent\n",
      " |      pydantic.v1.main.BaseModel\n",
      " |      pydantic.v1.utils.Representation\n",
      " |      llama_index.core.instrumentation.DispatcherSpanMixin\n",
      " |      abc.ABC\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, model_name: Optional[str] = None, tokenizer_name: Optional[str] = None, pooling: Union[str, llama_index.embeddings.huggingface.pooling.Pooling] = 'cls', max_length: Optional[int] = None, query_instruction: Optional[str] = None, text_instruction: Optional[str] = None, normalize: bool = True, model: Optional[Any] = None, tokenizer: Optional[Any] = None, embed_batch_size: int = 10, cache_folder: Optional[str] = None, trust_remote_code: bool = False, device: Optional[str] = None, callback_manager: Optional[llama_index.core.callbacks.base.CallbackManager] = None, safe_serialization: Optional[bool] = None)\n",
      " |      Create a new model by parsing and validating input data from keyword arguments.\n",
      " |      \n",
      " |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  class_name() -> str from pydantic.v1.main.ModelMetaclass\n",
      " |      Get the class name, used as a unique ID in serialization.\n",
      " |      \n",
      " |      This provides a key that makes serialization robust against actual class\n",
      " |      name changes.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  __annotations__ = {'_device': <class 'str'>, '_model': typing.Any, '_t...\n",
      " |  \n",
      " |  __class_vars__ = set()\n",
      " |  \n",
      " |  __config__ = <class 'pydantic.v1.config.Config'>\n",
      " |  \n",
      " |  __custom_root_type__ = False\n",
      " |  \n",
      " |  __exclude_fields__ = {'callback_manager': True}\n",
      " |  \n",
      " |  __fields__ = {'cache_folder': ModelField(name='cache_folder', type=Opt...\n",
      " |  \n",
      " |  __hash__ = None\n",
      " |  \n",
      " |  __include_fields__ = None\n",
      " |  \n",
      " |  __post_root_validators__ = []\n",
      " |  \n",
      " |  __pre_root_validators__ = []\n",
      " |  \n",
      " |  __private_attributes__ = {'_device': ModelPrivateAttr(default=Pydantic...\n",
      " |  \n",
      " |  __schema_cache__ = {}\n",
      " |  \n",
      " |  __signature__ = <Signature (model_name: Optional[str] = None, to...fe_...\n",
      " |  \n",
      " |  __validators__ = {'callback_manager': [<pydantic.v1.class_validators.V...\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from llama_index.core.base.embeddings.base.BaseEmbedding:\n",
      " |  \n",
      " |  __call__(self, nodes: List[llama_index.core.schema.BaseNode], **kwargs: Any) -> List[llama_index.core.schema.BaseNode]\n",
      " |  \n",
      " |  async acall(self, nodes: List[llama_index.core.schema.BaseNode], **kwargs: Any) -> List[llama_index.core.schema.BaseNode]\n",
      " |      Async transform nodes.\n",
      " |  \n",
      " |  async aget_agg_embedding_from_queries(self, queries: List[str], agg_fn: Optional[Callable[..., List[float]]] = None) -> List[float]\n",
      " |      Async get aggregated embedding from multiple queries.\n",
      " |  \n",
      " |  async aget_query_embedding(self, query: str) -> List[float]\n",
      " |      Get query embedding.\n",
      " |  \n",
      " |  async aget_text_embedding(self, text: str) -> List[float]\n",
      " |      Async get text embedding.\n",
      " |  \n",
      " |  async aget_text_embedding_batch(self, texts: List[str], show_progress: bool = False) -> List[List[float]]\n",
      " |      Asynchronously get a list of text embeddings, with batching.\n",
      " |  \n",
      " |  get_agg_embedding_from_queries(self, queries: List[str], agg_fn: Optional[Callable[..., List[float]]] = None) -> List[float]\n",
      " |      Get aggregated embedding from multiple queries.\n",
      " |  \n",
      " |  get_query_embedding(self, query: str) -> List[float]\n",
      " |      Embed the input query.\n",
      " |      \n",
      " |      When embedding a query, depending on the model, a special instruction\n",
      " |      can be prepended to the raw query string. For example, \"Represent the\n",
      " |      question for retrieving supporting documents: \". If you're curious,\n",
      " |      other examples of predefined instructions can be found in\n",
      " |      embeddings/huggingface_utils.py.\n",
      " |  \n",
      " |  get_text_embedding(self, text: str) -> List[float]\n",
      " |      Embed the input text.\n",
      " |      \n",
      " |      When embedding text, depending on the model, a special instruction\n",
      " |      can be prepended to the raw text string. For example, \"Represent the\n",
      " |      document for retrieval: \". If you're curious, other examples of\n",
      " |      predefined instructions can be found in embeddings/huggingface_utils.py.\n",
      " |  \n",
      " |  get_text_embedding_batch(self, texts: List[str], show_progress: bool = False, **kwargs: Any) -> List[List[float]]\n",
      " |      Get a list of text embeddings, with batching.\n",
      " |  \n",
      " |  similarity(self, embedding1: List[float], embedding2: List[float], mode: llama_index.core.base.embeddings.base.SimilarityMode = <SimilarityMode.DEFAULT: 'cosine'>) -> float\n",
      " |      Get embedding similarity.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from llama_index.core.base.embeddings.base.BaseEmbedding:\n",
      " |  \n",
      " |  Config = <class 'llama_index.core.base.embeddings.base.BaseEmbedding.C...\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from llama_index.core.schema.TransformComponent:\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from llama_index.core.schema.BaseComponent:\n",
      " |  \n",
      " |  __getstate__(self) -> Dict[str, Any]\n",
      " |  \n",
      " |  __setstate__(self, state: Dict[str, Any]) -> None\n",
      " |  \n",
      " |  dict(self, **kwargs: Any) -> Dict[str, Any]\n",
      " |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      " |  \n",
      " |  json(self, **kwargs: Any) -> str\n",
      " |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      " |      \n",
      " |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      " |  \n",
      " |  to_dict(self, **kwargs: Any) -> Dict[str, Any]\n",
      " |  \n",
      " |  to_json(self, **kwargs: Any) -> str\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from llama_index.core.schema.BaseComponent:\n",
      " |  \n",
      " |  from_dict(data: Dict[str, Any], **kwargs: Any) -> typing_extensions.Self from pydantic.v1.main.ModelMetaclass\n",
      " |      # TODO: return type here not supported by current mypy version\n",
      " |  \n",
      " |  from_json(data_str: str, **kwargs: Any) -> typing_extensions.Self from pydantic.v1.main.ModelMetaclass\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pydantic.v1.main.BaseModel:\n",
      " |  \n",
      " |  __eq__(self, other: Any) -> bool\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __iter__(self) -> 'TupleGenerator'\n",
      " |      so `dict(model)` works\n",
      " |  \n",
      " |  __repr_args__(self) -> 'ReprArgs'\n",
      " |      Returns the attributes to show in __str__, __repr__, and __pretty__ this is generally overridden.\n",
      " |      \n",
      " |      Can either return:\n",
      " |      * name - value pairs, e.g.: `[('foo_name', 'foo'), ('bar_name', ['b', 'a', 'r'])]`\n",
      " |      * or, just values, e.g.: `[(None, 'foo'), (None, ['b', 'a', 'r'])]`\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Implement setattr(self, name, value).\n",
      " |  \n",
      " |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      " |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      " |      \n",
      " |      :param include: fields to include in new model\n",
      " |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      " |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      " |          the new model: you should trust this data\n",
      " |      :param deep: set to `True` to make a deep copy of the model\n",
      " |      :return: new model instance\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from pydantic.v1.main.BaseModel:\n",
      " |  \n",
      " |  __get_validators__() -> 'CallableGenerator' from pydantic.v1.main.ModelMetaclass\n",
      " |  \n",
      " |  __try_update_forward_refs__(**localns: Any) -> None from pydantic.v1.main.ModelMetaclass\n",
      " |      Same as update_forward_refs but will not raise exception\n",
      " |      when forward references are not defined.\n",
      " |  \n",
      " |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from pydantic.v1.main.ModelMetaclass\n",
      " |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      " |      Default values are respected, but no other validation is performed.\n",
      " |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      " |  \n",
      " |  from_orm(obj: Any) -> 'Model' from pydantic.v1.main.ModelMetaclass\n",
      " |  \n",
      " |  parse_file(path: Union[str, pathlib.Path], *, content_type: str = None, encoding: str = 'utf8', proto: pydantic.v1.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.v1.main.ModelMetaclass\n",
      " |  \n",
      " |  parse_obj(obj: Any) -> 'Model' from pydantic.v1.main.ModelMetaclass\n",
      " |  \n",
      " |  parse_raw(b: Union[str, bytes], *, content_type: str = None, encoding: str = 'utf8', proto: pydantic.v1.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.v1.main.ModelMetaclass\n",
      " |  \n",
      " |  schema(by_alias: bool = True, ref_template: str = '#/definitions/{model}') -> 'DictStrAny' from pydantic.v1.main.ModelMetaclass\n",
      " |  \n",
      " |  schema_json(*, by_alias: bool = True, ref_template: str = '#/definitions/{model}', **dumps_kwargs: Any) -> str from pydantic.v1.main.ModelMetaclass\n",
      " |  \n",
      " |  update_forward_refs(**localns: Any) -> None from pydantic.v1.main.ModelMetaclass\n",
      " |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      " |  \n",
      " |  validate(value: Any) -> 'Model' from pydantic.v1.main.ModelMetaclass\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pydantic.v1.main.BaseModel:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __fields_set__\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pydantic.v1.utils.Representation:\n",
      " |  \n",
      " |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      " |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      " |  \n",
      " |  __repr__(self) -> str\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __repr_name__(self) -> str\n",
      " |      Name of the instance's class, used in __repr__.\n",
      " |  \n",
      " |  __repr_str__(self, join_str: str) -> str\n",
      " |  \n",
      " |  __rich_repr__(self) -> 'RichReprResult'\n",
      " |      Get fields for Rich library\n",
      " |  \n",
      " |  __str__(self) -> str\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from llama_index.core.instrumentation.DispatcherSpanMixin:\n",
      " |  \n",
      " |  __init_subclass__(**kwargs: Any) -> None from pydantic.v1.main.ModelMetaclass\n",
      " |      This method is called when a class is subclassed.\n",
      " |      \n",
      " |      The default implementation does nothing. It may be\n",
      " |      overridden to extend subclasses.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(HuggingFaceEmbedding)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "onnx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"

[tool.poetry]
name = "pai_rag"
version = "0.1.0"
description = "Open source RAG framework built on Aliyun PAI"
authors = []
readme = "README.md"

[tool.poetry.dependencies]
python = ">=3.10.0,<3.12"
fastapi = "^0.110.1"
uvicorn = "^0.29.0"
llama-index-core = ">=0.10.29,<=0.10.39"
llama-index-embeddings-openai = "^0.1.7"
llama-index-embeddings-azure-openai = "^0.1.7"
llama-index-embeddings-dashscope = "^0.1.3"
llama-index-llms-openai = "^0.1.15"
llama-index-llms-azure-openai = "^0.1.6"
llama-index-llms-dashscope = "^0.1.2"
llama-index-readers-database = "^0.1.3"
llama-index-vector-stores-chroma = "^0.1.6"
llama-index-vector-stores-faiss = "^0.1.2"
llama-index-vector-stores-analyticdb = "^0.1.1"
llama-index-vector-stores-elasticsearch = "^0.2.0"
llama-index-vector-stores-milvus = "^0.1.10"
gradio = "3.41.0"
faiss-cpu = "^1.8.0"
hologres-vector = "^0.0.9"
dynaconf = "^3.2.5"
docx2txt = "^0.8"
click = "^8.1.7"
pydantic = "^2.7.0"
pytest = "^8.1.1"
llama-index-retrievers-bm25 = "^0.1.3"
jieba = "^0.42.1"
llama-index-embeddings-huggingface = "^0.2.0"
llama-index-postprocessor-flag-embedding-reranker = "^0.1.3"
flagembedding = "^1.2.10"
sentencepiece = "^0.2.0"
oss2 = "^2.18.5"
asgi-correlation-id = "^4.3.1"
openinference-instrumentation-llama-index = "1.3.0"
torch = [
  {version = "2.3.0+cpu", source = "pytorch_cpu", platform = "linux"},
  {version = "2.3.0+cpu", source = "pytorch_cpu", platform = "win32"},
  {version = "2.2.2", platform = "darwin"}
]
torchvision = [
  {version = "0.18.0+cpu", source = "pytorch_cpu", platform = "linux"},
  {version = "0.18.0+cpu", source = "pytorch_cpu", platform = "win32"},
  {version = "0.17.2", platform = "darwin"}
]
openpyxl = "^3.1.2"
pdf2image = "^1.17.0"
llama-index-storage-chat-store-redis = "^0.1.3"
easyocr = "^1.7.1"
opencv-python = "^4.9.0.80"
llama-parse = "0.4.2"
pypdf2 = "^3.0.1"
pdfplumber = "^0.11.0"
pdfminer-six = "^20231228"
openinference-semantic-conventions = "0.1.6"
llama-index-tools-google = "^0.1.5"
llama-index-tools-duckduckgo = "^0.1.1"
openinference-instrumentation = "^0.1.7"
llama-index-llms-huggingface = "^0.2.0"
pytest-asyncio = "^0.23.7"
pytest-cov = "^5.0.0"
xlrd = "^2.0.1"
markdown = "^3.6"
chardet = "^5.2.0"
locust = "^2.29.0"
gunicorn = "^22.0.0"
protobuf = "3.20.0"

[tool.poetry.scripts]
pai_rag = "pai_rag.main:main"
load_data = "pai_rag.data.rag_datapipeline:run"
load_easyocr_model = "pai_rag.utils.download_easyocr_models:download_easyocr_models"
evaluation = "pai_rag.evaluation.eval_pipeline:run"

[[tool.poetry.source]]
name = "pytorch_cpu"
url = "https://download.pytorch.org/whl/cpu"
priority = "explicit"

[tool.pytest.ini_options]
asyncio_mode = "auto"
